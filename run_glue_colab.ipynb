{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate accelerate\n",
    "!pip install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "import shutil\n",
    "shutil.copy(\"/content/drive/MyDrive/Masterarbeit/fantastic-umbrella/run_glue_no_trainer_modded.py\", \"/content/run_glue_no_trainer_modded.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "print(f'torch Version {torch.__version__}')\n",
    "import transformers\n",
    "print(f'transformers Version {transformers.__version__}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Declare all possible parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_values = {\n",
    "    \"task\" : ['wnli', 'rte'],\n",
    "    \"learning_rate\" : [5e-5, 1e-5],\n",
    "    \"hidden_dropout\" : [0.1, 0.5, 0.8],\n",
    "    \"use_pretrain_dropout_in_first_pass\" : [True, False],\n",
    "    \"train_data_frac\" : [1, 0.5, 0.1],\n",
    "    \"use_modded\" : [True, False],\n",
    "    \"num_train_epochs\" : [5, 10, 20]\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an exhaustive list of all parameter combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "keys, values = zip(*possible_values.items())\n",
    "permutations_dicts = [dict(zip(keys, v)) for v in product(*values)]\n",
    "print(len(permutations_dicts))\n",
    "permutations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorboard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Load the TensorBoard notebook extension\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mload_ext\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtensorboard\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Valentin\\miniconda3\\envs\\fantastic-umbrella\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2417\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2415\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2416\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2417\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2419\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2420\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2421\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2422\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\Valentin\\miniconda3\\envs\\fantastic-umbrella\\lib\\site-packages\\IPython\\core\\magics\\extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m module_str:\n\u001b[0;32m     32\u001b[0m     \u001b[39mraise\u001b[39;00m UsageError(\u001b[39m'\u001b[39m\u001b[39mMissing module name.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49mextension_manager\u001b[39m.\u001b[39;49mload_extension(module_str)\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39malready loaded\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m extension is already loaded. To reload it, use:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m module_str)\n",
      "File \u001b[1;32mc:\\Users\\Valentin\\miniconda3\\envs\\fantastic-umbrella\\lib\\site-packages\\IPython\\core\\extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[39mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[39m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[39mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_extension(module_str)\n\u001b[0;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[1;32mc:\\Users\\Valentin\\miniconda3\\envs\\fantastic-umbrella\\lib\\site-packages\\IPython\\core\\extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmodules:\n\u001b[1;32m---> 91\u001b[0m         mod \u001b[39m=\u001b[39m import_module(module_str)\n\u001b[0;32m     92\u001b[0m     mod \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[module_str]\n\u001b[0;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[1;32mc:\\Users\\Valentin\\miniconda3\\envs\\fantastic-umbrella\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"/content/drive/MyDrive/Masterarbeit/fantastic-umbrella/runs/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the script command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['--model_name_or_path', 'bert-base-cased', '--max_length', '128', '--per_device_train_batch_size', '32', '--seed', '0', '--with_tracking', '--report_to tensorboard', '--task_name', 'WNLI', '--num_train_epochs', '5', '--learning_rate', '5e-05', '--train_data_frac', '1', '--hidden_dropout', '0.1', '--use_modded', '--use_pretrain_dropout_in_first_pass', '--output_dir', '/content/drive/MyDrive/Masterarbeit/fantastic-umbrella/runs/run-20230614_121442']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 39\u001b[0m\n\u001b[0;32m     35\u001b[0m instruction \u001b[39m=\u001b[39m base_command \u001b[39m+\u001b[39m argument_string\n\u001b[0;32m     36\u001b[0m \u001b[39m# print(instruction)\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \n\u001b[0;32m     38\u001b[0m \u001b[39m# run the script with the desired arguments\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m os\u001b[39m.\u001b[39;49msystem(instruction)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import os\n",
    "for iteration, parameters in enumerate(permutations_dicts):\n",
    "    print(f'##################################### Current iteration: {iteration} #####################################')\n",
    "    base_command = 'python run_glue_no_trainer_modded.py '\n",
    "    argument_list = [\"--model_name_or_path\", \"bert-base-cased\",\n",
    "                     \"--max_length\", \"128\",\n",
    "                     \"--per_device_train_batch_size\", \"32\",\n",
    "                     \"--seed\", \"0\",\n",
    "                     \"--with_tracking\",\n",
    "                     \"--report_to tensorboard\"\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "    argument_list = argument_list + [\"--task_name\", f'{parameters[\"task\"]}']\n",
    "    argument_list = argument_list + [\"--num_train_epochs\", f'{parameters[\"num_train_epochs\"]}']\n",
    "    argument_list = argument_list + [\"--learning_rate\", f'{parameters[\"learning_rate\"]}']\n",
    "    argument_list = argument_list + [\"--train_data_frac\", f'{parameters[\"train_data_frac\"]}']\n",
    "    argument_list = argument_list + [\"--hidden_dropout\", f'{parameters[\"hidden_dropout\"]}']\n",
    "\n",
    "\n",
    "    if parameters[\"use_modded\"]:\n",
    "        argument_list.append(\"--use_modded\")\n",
    "\n",
    "    if parameters[\"use_pretrain_dropout_in_first_pass\"]:\n",
    "        argument_list.append(\"--use_pretrain_dropout_in_first_pass\")\n",
    "    \n",
    "    folder_name = 'run-{date:%Y%m%d_%H%M%S}'.format( date=datetime.datetime.now() )\n",
    "    output_dir = f\"/content/drive/MyDrive/Masterarbeit/fantastic-umbrella/runs/{folder_name}\"\n",
    "    argument_list = argument_list + [\"--output_dir\",output_dir]\n",
    "    # print(argument_list)\n",
    "    argument_string = ' '.join(argument_list)\n",
    "    # print(argument_string)\n",
    "    instruction = base_command + argument_string\n",
    "    # print(instruction)\n",
    "\n",
    "    # run the script with the desired arguments\n",
    "    # os.system(instruction) # vscode style\n",
    "    !{instruction} # colab style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Der Befehl \"bash\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "!bash run_modded.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "for path,_,files in os.walk('/content'):\n",
    "    for file in fnmatch.filter(files,'pytorch_model.bin'):\n",
    "        fullname = os.path.abspath(os.path.join(path,file))\n",
    "        os.remove(fullname)\n",
    "        print(f'removed {fullname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the modded runs\n",
    "!zip -r '/content/mod_runs.zip' '/content/mod_runs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash run_vanilla.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the vanilla runs\n",
    "!zip -r '/content/vanilla_runs.zip' '/content/vanilla_runs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('/content/vanilla_runs.zip') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantastic-umbrella",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
