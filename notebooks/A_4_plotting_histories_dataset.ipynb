{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns \n",
    "import functools\n",
    "import operator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>State</th>\n",
       "      <th>Notes</th>\n",
       "      <th>User</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Created</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Sweep</th>\n",
       "      <th>ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>...</th>\n",
       "      <th>test_f1_best_eval_loss</th>\n",
       "      <th>test_f1_best_f1</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_p_max</th>\n",
       "      <th>train_p_var</th>\n",
       "      <th>train_st1_loss</th>\n",
       "      <th>train_st1_p_max</th>\n",
       "      <th>train_st2_loss</th>\n",
       "      <th>train_st2_p_max</th>\n",
       "      <th>vector_norms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27_S5_ID_14_VAN</td>\n",
       "      <td>killed</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP5, vanilla</td>\n",
       "      <td>2024-01-14T10:19:14.000Z</td>\n",
       "      <td>203</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ab44uapw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100195</td>\n",
       "      <td>0.905648</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27_S5_ID_13_VAN</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP5, vanilla</td>\n",
       "      <td>2024-01-14T10:11:31.000Z</td>\n",
       "      <td>438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hrvhvkw7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010143</td>\n",
       "      <td>0.989919</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27_S5_ID_12_VAN</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP5, vanilla</td>\n",
       "      <td>2024-01-14T10:03:58.000Z</td>\n",
       "      <td>428</td>\n",
       "      <td>NaN</td>\n",
       "      <td>o21sms9h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012322</td>\n",
       "      <td>0.987801</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27_S5_ID_11_VAN</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP5, vanilla</td>\n",
       "      <td>2024-01-14T09:45:41.000Z</td>\n",
       "      <td>1073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ozlvjk8w</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.998156</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27_S5_ID_10_VAN</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP5, vanilla</td>\n",
       "      <td>2024-01-14T09:38:54.000Z</td>\n",
       "      <td>384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tj7hs264</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>0.990293</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>27_S0_ID_04_MOD</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP0, modded</td>\n",
       "      <td>2024-01-14T00:18:21.000Z</td>\n",
       "      <td>237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5y4ufaf2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.999371</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.998647</td>\n",
       "      <td>{\"_type\":\"histogram\",\"bins\":[0.000002224890522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>27_S0_ID_03_MOD</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP0, modded</td>\n",
       "      <td>2024-01-14T00:10:26.000Z</td>\n",
       "      <td>451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nhuruz8h</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.008447</td>\n",
       "      <td>0.999218</td>\n",
       "      <td>{\"_type\":\"histogram\",\"bins\":[0.000002546078121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>27_S0_ID_02_MOD</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP0, modded</td>\n",
       "      <td>2024-01-14T00:04:48.000Z</td>\n",
       "      <td>313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>emk1mo4s</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.999722</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.999486</td>\n",
       "      <td>{\"_type\":\"histogram\",\"bins\":[2.043253601868855...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>27_S0_ID_01_MOD</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP0, modded</td>\n",
       "      <td>2024-01-13T23:59:52.000Z</td>\n",
       "      <td>273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kc8vz17i</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.999504</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.998186</td>\n",
       "      <td>{\"_type\":\"histogram\",\"bins\":[1.524182522416595...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>27_S0_ID_00_MOD</td>\n",
       "      <td>finished</td>\n",
       "      <td>-</td>\n",
       "      <td>ricu</td>\n",
       "      <td>SWP0, modded</td>\n",
       "      <td>2024-01-13T23:56:54.000Z</td>\n",
       "      <td>154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6vp7kl02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000929</td>\n",
       "      <td>0.999072</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.998084</td>\n",
       "      <td>{\"_type\":\"histogram\",\"bins\":[1.905275013314167...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name     State Notes  User           Tags  \\\n",
       "0    27_S5_ID_14_VAN    killed     -  ricu  SWP5, vanilla   \n",
       "1    27_S5_ID_13_VAN  finished     -  ricu  SWP5, vanilla   \n",
       "2    27_S5_ID_12_VAN  finished     -  ricu  SWP5, vanilla   \n",
       "3    27_S5_ID_11_VAN  finished     -  ricu  SWP5, vanilla   \n",
       "4    27_S5_ID_10_VAN  finished     -  ricu  SWP5, vanilla   \n",
       "..               ...       ...   ...   ...            ...   \n",
       "100  27_S0_ID_04_MOD  finished     -  ricu   SWP0, modded   \n",
       "101  27_S0_ID_03_MOD  finished     -  ricu   SWP0, modded   \n",
       "102  27_S0_ID_02_MOD  finished     -  ricu   SWP0, modded   \n",
       "103  27_S0_ID_01_MOD  finished     -  ricu   SWP0, modded   \n",
       "104  27_S0_ID_00_MOD  finished     -  ricu   SWP0, modded   \n",
       "\n",
       "                      Created  Runtime  Sweep        ID  Group  ...  \\\n",
       "0    2024-01-14T10:19:14.000Z      203    NaN  ab44uapw    NaN  ...   \n",
       "1    2024-01-14T10:11:31.000Z      438    NaN  hrvhvkw7    NaN  ...   \n",
       "2    2024-01-14T10:03:58.000Z      428    NaN  o21sms9h    NaN  ...   \n",
       "3    2024-01-14T09:45:41.000Z     1073    NaN  ozlvjk8w    NaN  ...   \n",
       "4    2024-01-14T09:38:54.000Z      384    NaN  tj7hs264    NaN  ...   \n",
       "..                        ...      ...    ...       ...    ...  ...   \n",
       "100  2024-01-14T00:18:21.000Z      237    NaN  5y4ufaf2    NaN  ...   \n",
       "101  2024-01-14T00:10:26.000Z      451    NaN  nhuruz8h    NaN  ...   \n",
       "102  2024-01-14T00:04:48.000Z      313    NaN  emk1mo4s    NaN  ...   \n",
       "103  2024-01-13T23:59:52.000Z      273    NaN  kc8vz17i    NaN  ...   \n",
       "104  2024-01-13T23:56:54.000Z      154    NaN  6vp7kl02    NaN  ...   \n",
       "\n",
       "     test_f1_best_eval_loss test_f1_best_f1 train_loss train_p_max  \\\n",
       "0                       NaN             NaN        NaN         NaN   \n",
       "1                       NaN             NaN        NaN         NaN   \n",
       "2                       NaN             NaN        NaN         NaN   \n",
       "3                       NaN             NaN        NaN         NaN   \n",
       "4                       NaN             NaN        NaN         NaN   \n",
       "..                      ...             ...        ...         ...   \n",
       "100                     NaN             NaN        NaN         NaN   \n",
       "101                     NaN             NaN        NaN         NaN   \n",
       "102                     NaN             NaN        NaN         NaN   \n",
       "103                     NaN             NaN        NaN         NaN   \n",
       "104                     NaN             NaN        NaN         NaN   \n",
       "\n",
       "     train_p_var  train_st1_loss  train_st1_p_max  train_st2_loss  \\\n",
       "0            NaN             NaN              NaN        0.100195   \n",
       "1            NaN             NaN              NaN        0.010143   \n",
       "2            NaN             NaN              NaN        0.012322   \n",
       "3            NaN             NaN              NaN        0.001846   \n",
       "4            NaN             NaN              NaN        0.009770   \n",
       "..           ...             ...              ...             ...   \n",
       "100          NaN        0.000630         0.999371        0.001358   \n",
       "101          NaN        0.000363         0.999637        0.008447   \n",
       "102          NaN        0.000278         0.999722        0.000514   \n",
       "103          NaN        0.000496         0.999504        0.002935   \n",
       "104          NaN        0.000929         0.999072        0.006299   \n",
       "\n",
       "    train_st2_p_max                                       vector_norms  \n",
       "0          0.905648                                                NaN  \n",
       "1          0.989919                                                NaN  \n",
       "2          0.987801                                                NaN  \n",
       "3          0.998156                                                NaN  \n",
       "4          0.990293                                                NaN  \n",
       "..              ...                                                ...  \n",
       "100        0.998647  {\"_type\":\"histogram\",\"bins\":[0.000002224890522...  \n",
       "101        0.999218  {\"_type\":\"histogram\",\"bins\":[0.000002546078121...  \n",
       "102        0.999486  {\"_type\":\"histogram\",\"bins\":[2.043253601868855...  \n",
       "103        0.998186  {\"_type\":\"histogram\",\"bins\":[1.524182522416595...  \n",
       "104        0.998084  {\"_type\":\"histogram\",\"bins\":[1.905275013314167...  \n",
       "\n",
       "[105 rows x 111 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_wandb_csv(loc):\n",
    "    df = pd.read_csv(loc)\n",
    "    df.param_config_id = df.param_config_id.astype('str')\n",
    "    return df\n",
    "\n",
    "id_df = read_wandb_csv(\"data/A_4_dataset_choice_test.csv\")\n",
    "id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/105 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105/105 [04:19<00:00,  2.47s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "run_ids = id_df[\"ID\"]\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "all_dfs = []\n",
    "metrics_train = [\"train_st2_loss\"]\n",
    "metrics_eval = [\"accuracy\",\"eval_loss\",\"eval_p_max\"]\n",
    "metrics_lr = [\"learning_rate\"]\n",
    "index_keys = [\"_step\",\"epoch\"]\n",
    "\n",
    "# Add tqdm to the loop for progress bar\n",
    "for run_id in tqdm(run_ids):\n",
    "    run = api.run(f\"ricu/fantastic-umbrella/{run_id}\")\n",
    "    \n",
    "    # Fetch the history\n",
    "    history_train = run.scan_history(keys=metrics_train+index_keys)\n",
    "    df_run =  pd.DataFrame([row for row in history_train])\n",
    "    \n",
    "    history_eval = run.scan_history(keys=metrics_eval+index_keys)\n",
    "    df_run = df_run.merge(pd.DataFrame([row for row in history_eval]), on=['_step', 'epoch'], how='outer')\n",
    "    \n",
    "    history_lr = run.scan_history(keys=metrics_lr+index_keys)\n",
    "    df_run = df_run.merge(pd.DataFrame([row for row in history_lr]), on=['_step', 'epoch'], how='outer')\n",
    "    df_run = df_run.sort_values(by=\"_step\", ascending=True,ignore_index=True)\n",
    "    # last_step_diff = df_run[\"_step\"].iloc[-1] - df_run[\"_step\"].iloc[-2]\n",
    "    # first_step_diff = df_run[\"_step\"].iloc[1] - df_run[\"_step\"].iloc[0]\n",
    "    # if last_step_diff != first_step_diff:\n",
    "    #     df_run.at[df_run.index[-1], 'train_st2_loss'] = df_run['train_st2_loss'].iloc[-1] / last_step_diff\n",
    "    df_run[\"learning_rate\"] = df_run[\"learning_rate\"].fillna(0)\n",
    "\n",
    "    for key, value in run.config.items():\n",
    "        df_run = df_run.assign(**{key: value})\n",
    "    \n",
    "    all_dfs.append(df_run)\n",
    "\n",
    "df = pd.concat(all_dfs,axis=0,ignore_index=True)\n",
    "df[\"mode\"] = df[\"catch_dropout\"].fillna(1).map({0: 'FUMBRELLA', 1: 'VANILLA'})\n",
    "with open(\"data/A_4_dataset.pkl\",'wb') as f:\n",
    "    pickle.dump(df,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_st2_loss</th>\n",
       "      <th>_step</th>\n",
       "      <th>epoch</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_p_max</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>seed</th>\n",
       "      <th>beta1</th>\n",
       "      <th>beta2</th>\n",
       "      <th>...</th>\n",
       "      <th>num_warmup_steps</th>\n",
       "      <th>lr_scheduler_type</th>\n",
       "      <th>pad_to_max_length</th>\n",
       "      <th>model_name_or_path</th>\n",
       "      <th>warmup_steps_fraction</th>\n",
       "      <th>early_stopping_patience</th>\n",
       "      <th>ignore_mismatched_sizes</th>\n",
       "      <th>early_stopping_min_delta</th>\n",
       "      <th>per_device_eval_batch_size</th>\n",
       "      <th>per_device_train_batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.453613</td>\n",
       "      <td>0.806656</td>\n",
       "      <td>0.662279</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>linear</td>\n",
       "      <td>False</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.821650</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.454590</td>\n",
       "      <td>0.804965</td>\n",
       "      <td>0.660702</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>linear</td>\n",
       "      <td>False</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.780583</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.454590</td>\n",
       "      <td>0.798809</td>\n",
       "      <td>0.654897</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>linear</td>\n",
       "      <td>False</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.775312</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0.458496</td>\n",
       "      <td>0.788556</td>\n",
       "      <td>0.644111</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>linear</td>\n",
       "      <td>False</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.752005</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>0.459473</td>\n",
       "      <td>0.774892</td>\n",
       "      <td>0.627778</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.999</td>\n",
       "      <td>...</td>\n",
       "      <td>80</td>\n",
       "      <td>linear</td>\n",
       "      <td>False</td>\n",
       "      <td>bert-base-uncased</td>\n",
       "      <td>0.1</td>\n",
       "      <td>40</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_st2_loss  _step  epoch  accuracy  eval_loss  eval_p_max  \\\n",
       "0             NaN      0     -1  0.453613   0.806656    0.662279   \n",
       "1        0.821650      4      1  0.454590   0.804965    0.660702   \n",
       "2        0.780583      8      3  0.454590   0.798809    0.654897   \n",
       "3        0.775312     12      5  0.458496   0.788556    0.644111   \n",
       "4        0.752005     16      7  0.459473   0.774892    0.627778   \n",
       "\n",
       "   learning_rate  seed  beta1  beta2  ... num_warmup_steps lr_scheduler_type  \\\n",
       "0        0.00003     3    0.9  0.999  ...               80            linear   \n",
       "1        0.00003     3    0.9  0.999  ...               80            linear   \n",
       "2        0.00003     3    0.9  0.999  ...               80            linear   \n",
       "3        0.00003     3    0.9  0.999  ...               80            linear   \n",
       "4        0.00003     3    0.9  0.999  ...               80            linear   \n",
       "\n",
       "   pad_to_max_length model_name_or_path warmup_steps_fraction  \\\n",
       "0              False  bert-base-uncased                   0.1   \n",
       "1              False  bert-base-uncased                   0.1   \n",
       "2              False  bert-base-uncased                   0.1   \n",
       "3              False  bert-base-uncased                   0.1   \n",
       "4              False  bert-base-uncased                   0.1   \n",
       "\n",
       "   early_stopping_patience  ignore_mismatched_sizes early_stopping_min_delta  \\\n",
       "0                       40                    False                        0   \n",
       "1                       40                    False                        0   \n",
       "2                       40                    False                        0   \n",
       "3                       40                    False                        0   \n",
       "4                       40                    False                        0   \n",
       "\n",
       "   per_device_eval_batch_size  per_device_train_batch_size  \n",
       "0                         128                           32  \n",
       "1                         128                           32  \n",
       "2                         128                           32  \n",
       "3                         128                           32  \n",
       "4                         128                           32  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"data/A_4_dataset.pkl\",'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qnli 1e-05\n",
      "                                   mean    median       std\n",
      "task_name learning_rate _step                              \n",
      "qnli      0.00001       800    0.724772  0.727051  0.010922\n",
      "                        784    0.725098  0.727051  0.010392\n",
      "                        768    0.723511  0.723145  0.008783\n",
      "                        752    0.723633  0.723389  0.009187\n",
      "                        736    0.723633  0.723389  0.009187\n",
      "                        720    0.727051  0.729004  0.011199\n",
      "                        704    0.727539  0.729004  0.010847\n",
      "                        688    0.727441  0.729004  0.010937\n",
      "                        672    0.727539  0.729980  0.010836\n",
      "                        656    0.727930  0.731445  0.011541\n",
      "                        640    0.727344  0.730469  0.011506\n",
      "                        624    0.727637  0.729980  0.011195\n",
      "                        608    0.727441  0.729980  0.011163\n",
      "                        592    0.726953  0.729004  0.011110\n",
      "                        576    0.726074  0.727539  0.011855\n",
      "                        560    0.727734  0.729980  0.013267\n",
      "                        544    0.726888  0.727539  0.012161\n",
      "                        528    0.727051  0.728027  0.011840\n",
      "                        512    0.728167  0.730957  0.012445\n",
      "                        496    0.726632  0.730957  0.013257\n",
      "                        480    0.725586  0.728027  0.013558\n",
      "                        464    0.725656  0.729004  0.013562\n",
      "                        448    0.726423  0.730957  0.013204\n",
      "                        432    0.726144  0.727539  0.012389\n",
      "                        416    0.727330  0.729492  0.010649\n",
      "                        400    0.727121  0.729004  0.011449\n",
      "                        384    0.726562  0.728516  0.010926\n",
      "                        368    0.725725  0.727051  0.011745\n",
      "                        352    0.723912  0.725098  0.013077\n",
      "                        336    0.703552  0.715576  0.050147\n",
      "                        320    0.704861  0.713867  0.049452\n",
      "                        304    0.704698  0.714355  0.048559\n",
      "                        288    0.705132  0.718262  0.048962\n",
      "                        272    0.708008  0.718750  0.042115\n",
      "                        256    0.703885  0.715332  0.047829\n",
      "                        240    0.703885  0.713867  0.044816\n",
      "                        224    0.704210  0.712891  0.044827\n",
      "                        208    0.705675  0.717773  0.037888\n",
      "                        192    0.707520  0.716309  0.029431\n",
      "                        176    0.707954  0.708984  0.025544\n",
      "                        160    0.702474  0.709961  0.029463\n",
      "                        144    0.699273  0.707031  0.027812\n",
      "                        128    0.689670  0.704102  0.036030\n",
      "                        112    0.677734  0.694824  0.044187\n",
      "                        96     0.667860  0.681152  0.043962\n",
      "                        80     0.649523  0.677246  0.058754\n",
      "                        64     0.608344  0.667480  0.095470\n",
      "                        48     0.545953  0.504883  0.078836\n",
      "                        32     0.518338  0.498535  0.052720\n",
      "                        16     0.501139  0.496094  0.040301\n",
      "                        0      0.495931  0.492188  0.038372\n",
      "qnli 5e-05\n",
      "                                   mean    median       std\n",
      "task_name learning_rate _step                              \n",
      "qnli      0.00005       800    0.735840  0.735840       NaN\n",
      "                        784    0.735840  0.735840       NaN\n",
      "                        768    0.735840  0.735840       NaN\n",
      "                        752    0.721924  0.721924  0.019680\n",
      "                        736    0.721680  0.721680  0.019335\n",
      "                        720    0.721924  0.721924  0.018990\n",
      "                        704    0.721924  0.721924  0.018990\n",
      "                        688    0.721924  0.721924  0.018990\n",
      "                        672    0.721924  0.721924  0.018990\n",
      "                        656    0.721924  0.721924  0.018990\n",
      "                        640    0.721680  0.721680  0.018644\n",
      "                        624    0.721924  0.721924  0.018990\n",
      "                        608    0.721924  0.721924  0.018990\n",
      "                        592    0.718913  0.712891  0.013951\n",
      "                        576    0.719401  0.713867  0.014028\n",
      "                        560    0.718750  0.713867  0.013845\n",
      "                        544    0.718424  0.713379  0.013657\n",
      "                        528    0.722534  0.723633  0.014596\n",
      "                        512    0.722290  0.723389  0.014542\n",
      "                        496    0.726660  0.732910  0.015349\n",
      "                        480    0.726855  0.732910  0.015084\n",
      "                        464    0.726660  0.732910  0.014703\n",
      "                        448    0.726855  0.732910  0.014446\n",
      "                        432    0.727148  0.732422  0.014166\n",
      "                        416    0.729492  0.734131  0.014306\n",
      "                        400    0.729411  0.733887  0.014643\n",
      "                        384    0.729655  0.734619  0.014670\n",
      "                        368    0.729655  0.734863  0.015103\n",
      "                        352    0.729004  0.733643  0.014993\n",
      "                        336    0.727748  0.731445  0.014479\n",
      "                        320    0.727400  0.729980  0.014631\n",
      "                        304    0.726214  0.728516  0.014489\n",
      "                        288    0.726632  0.729492  0.014368\n",
      "                        272    0.712457  0.725098  0.042602\n",
      "                        256    0.712728  0.724121  0.042170\n",
      "                        240    0.712185  0.723633  0.041366\n",
      "                        224    0.712294  0.724121  0.041588\n",
      "                        208    0.711806  0.724121  0.041210\n",
      "                        192    0.711860  0.723633  0.041286\n",
      "                        176    0.710612  0.719238  0.039456\n",
      "                        160    0.708496  0.717285  0.037319\n",
      "                        144    0.705024  0.713867  0.037826\n",
      "                        128    0.710829  0.716797  0.032470\n",
      "                        112    0.703668  0.713379  0.028577\n",
      "                        96     0.703396  0.717285  0.029298\n",
      "                        80     0.696452  0.710449  0.032514\n",
      "                        64     0.689616  0.690918  0.033572\n",
      "                        48     0.672201  0.692383  0.044804\n",
      "                        32     0.629829  0.672363  0.072741\n",
      "                        16     0.524685  0.500488  0.058276\n",
      "                        0      0.495931  0.492188  0.038372\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Level insert_dropout not found'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Valentin\\miniconda3\\envs\\fantastic-umbrella_2\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:1488\u001b[0m, in \u001b[0;36mMultiIndex._get_level_number\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m   1487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1488\u001b[0m     level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[1;31mValueError\u001b[0m: 'insert_dropout' is not in list",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 30\u001b[0m\n\u001b[0;32m     27\u001b[0m statistics \u001b[38;5;241m=\u001b[39m grouped_df[row_val]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m statistics \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39msort_index(level\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtask_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dropout_rate \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstatistics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minsert_dropout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39munique():\n\u001b[0;32m     31\u001b[0m     lr_stats \u001b[38;5;241m=\u001b[39m statistics\u001b[38;5;241m.\u001b[39mloc[dropout_rate]\n\u001b[0;32m     32\u001b[0m     axs[idx,idy]\u001b[38;5;241m.\u001b[39mplot(lr_stats\u001b[38;5;241m.\u001b[39mindex, lr_stats[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDropout Rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Valentin\\miniconda3\\envs\\fantastic-umbrella_2\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:1655\u001b[0m, in \u001b[0;36mMultiIndex.get_level_values\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m   1607\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_level_values\u001b[39m(\u001b[38;5;28mself\u001b[39m, level):\n\u001b[0;32m   1608\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1609\u001b[0m \u001b[38;5;124;03m    Return vector of label values for requested level.\u001b[39;00m\n\u001b[0;32m   1610\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1653\u001b[0m \u001b[38;5;124;03m    Index([1.0, nan, 2.0], dtype='float64')\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1655\u001b[0m     level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_level_number\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1656\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_level_values(level)\n\u001b[0;32m   1657\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[1;32mc:\\Users\\Valentin\\miniconda3\\envs\\fantastic-umbrella_2\\lib\\site-packages\\pandas\\core\\indexes\\multi.py:1491\u001b[0m, in \u001b[0;36mMultiIndex._get_level_number\u001b[1;34m(self, level)\u001b[0m\n\u001b[0;32m   1489\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m   1490\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_integer(level):\n\u001b[1;32m-> 1491\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLevel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1493\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnlevels\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Level insert_dropout not found'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x1400 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "selected_rows = functools.reduce(\n",
    "    operator.and_,\n",
    "    [\n",
    "        df[\"training_size\"] == 256\n",
    "        # df[\"Tags\"].str.contains('modded')\n",
    "    ]  \n",
    "    )\n",
    "filtered_df = df.loc[selected_rows]\n",
    "\n",
    "subplot_columns = sorted(df[\"mode\"].unique())\n",
    "subplot_rows = ['accuracy', 'eval_loss', 'train_st2_loss']\n",
    "\n",
    "# Create a new figure\n",
    "fig, axs = plt.subplots(\n",
    "    len(subplot_rows),\n",
    "    len(subplot_columns),\n",
    "    sharex=True,\n",
    "    sharey='row',\n",
    "    figsize = (14,14)\n",
    "    # figsize = (TEXTWIDTH,TEXTWIDTH)\n",
    "    )\n",
    "\n",
    "for idy, col_val in enumerate(subplot_columns):\n",
    "    for idx, row_val in enumerate(subplot_rows):\n",
    "        grouped_df = filtered_df.loc[df[\"mode\"]==col_val].groupby([\"task_name\",\"learning_rate\",\"_step\"])\n",
    "        statistics = grouped_df[row_val].agg(['mean', 'median', 'std'])\n",
    "        statistics = statistics.sort_index(level=[\"task_name\",\"learning_rate\"], ascending=False)\n",
    "\n",
    "        for (task_name, learning_rate), group in statistics.groupby(level=['task_name', 'learning_rate']):\n",
    "            axs[idx,idy].plot(\n",
    "                group.index.get_level_values('_step'),\n",
    "                group[\"median\"],\n",
    "                label=f'Dataset: {task_name}, Learning Rate: {learning_rate}'\n",
    "                )\n",
    "\n",
    "        if idy == 0:\n",
    "            axs[idx,idy].set_ylabel(row_val)\n",
    "        if idx == 0:\n",
    "            axs[idx,idy].set_title(f'Mode: {col_val}')\n",
    "        if idx == len(subplot_columns) - 1:\n",
    "            axs[idx,idy].set_xlabel('Step')\n",
    "\n",
    "        axs[idx,idy].grid(True,which='major')\n",
    "        axs[idx,idy].grid(True,which='minor')\n",
    "\n",
    "        if idx == 0:\n",
    "            axs[idx,idy].legend()\n",
    "\n",
    "\n",
    "fig.suptitle('Influence of the Dropout Rate (Training Set Size: 256)', fontsize=16,weight='bold')\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/A_3_dropout.pdf', format='pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantastic-umbrella_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
