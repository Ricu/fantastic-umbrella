{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_accelerate = False\n",
    "num_devices = 2 if use_accelerate else 1\n",
    "\n",
    "GENERATION = \"15_512_testing\"\n",
    "SWEEP_ID = 4\n",
    "DEVICE = 0\n",
    "base_dir = '/home/lange/fantastic-umbrella/runs'\n",
    "\n",
    "\n",
    "boolean_args = {\n",
    "    'with_tracking' : [True],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set run(s) parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.e-06 5.e-06 7.e-06 9.e-06 1.e-05 3.e-05 5.e-05]\n",
      "[0.01]\n",
      "[0.1  0.12 0.14 0.16 0.18 0.2  0.22 0.24]\n",
      "[0.0]\n",
      "[0.9]\n",
      "[0.999, 0.9999]\n",
      "[300, 600]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "l_learning_rate = 1e-6 * np.array([3,5,7,9,10,30,50])\n",
    "print(l_learning_rate)\n",
    "numbers = np.array([2,5,8])\n",
    "l_weight_decay = [0.01] #np.concatenate([0.001 * numbers, 0.01 * numbers, np.array([0.1])]) # 0.01\n",
    "print(l_weight_decay)\n",
    "l_insert_dropout = np.arange(0.1,0.25, 0.02) # 0.01\n",
    "print(l_insert_dropout) \n",
    "l_catch_dropout = [0.0] \n",
    "print(l_catch_dropout) \n",
    "l_beta_1 = [0.9]# np.arange(0.8,1,0.02) # 0.9\n",
    "print(l_beta_1)\n",
    "l_beta_2 = [0.999,0.9999]#[0.9,0.99,0.999,0.9999] # 0.999\n",
    "print(l_beta_2)\n",
    "l_num_train_epochs = [300,600]\n",
    "print(l_num_train_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_args ={\n",
    "    'task_name' : [\"qnli\"], #[\"cola\",\"sst2\",\"mrpc\",\"stsb\",\"qqp\",\"mnli\",\"rte\"],\n",
    "    'model_name_or_path' : ['bert-base-uncased'],\n",
    "    'per_device_train_batch_size' : [32],\n",
    "    'per_device_eval_batch_size' : [64],    \n",
    "    'weight_decay' : l_weight_decay,#[0.01],\n",
    "    # 'max_train_steps' : [15000],\n",
    "    'lr_scheduler_type' : ['linear'],\n",
    "    # 'num_warmup_steps' : [4000],\n",
    "    'warmup_steps_fraction' : [0.1],\n",
    "    'report_to' : ['all'],\n",
    "    'insert_dropout' : l_insert_dropout,#[0.1],\n",
    "    # 'catch_dropout' : l_catch_dropout,#[0,0.02],\n",
    "    'training_size' : [512],\n",
    "    'beta1' : l_beta_1,#[0.9],\n",
    "    'beta2' : l_beta_2,#[0.999],\n",
    "    'early_stopping_patience' : [100],\n",
    "    'early_stopping_min_delta' : [0],\n",
    "    'original_gradient_fraction' : [0],\n",
    "    'num_train_epochs' : l_num_train_epochs,\n",
    "    'learning_rate': l_learning_rate,# [5e-5,4e-5,3e-5,2e-5],\n",
    "    'evaluation_steps': [128]\n",
    "}\n",
    "# seeds = [0,1,2,3,4]\n",
    "seeds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# from pprint import pprint\n",
    "# api = wandb.Api()\n",
    "\n",
    "# pcids = []\n",
    "# run_names = []\n",
    "# for run in api.runs(\"ricu/fantastic-umbrella\"):\n",
    "#     if ('sweep_12a_00' in run.name) | ('sweep_12a_01' in run.name):\n",
    "#         run.config[\"run_generation\"] = GENERATION\n",
    "#         run.config[\"learning_rate\"] /= 2\n",
    "#         pcid = get_param_config_id(\n",
    "#             {k: run.config[k] for k in (list(value_args) + ['run_generation'])},\n",
    "#             insert_new=False\n",
    "#         )\n",
    "#         run.config[\"param_config_id\"] = pcid\n",
    "#         run.update()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_instruction(value_args, boolean_args, use_accelerate=False, device=0):\n",
    "    if use_accelerate:\n",
    "        instruction = 'accelerate launch run_glue_no_trainer_modded.py'\n",
    "    else:\n",
    "        # instruction = 'python run_glue_no_trainer_modded.py'\n",
    "        instruction = f'CUDA_VISIBLE_DEVICES={device} python run_glue_no_trainer_modded.py'\n",
    "\n",
    "    for k, v in value_args.items():\n",
    "        instruction += f' --{k} {v}'\n",
    "\n",
    "    for k, v in boolean_args.items():\n",
    "        if v:\n",
    "            instruction += f' --{k}'\n",
    "\n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "INDEX_FILE = 'run_index.csv'\n",
    "zfill = 4\n",
    "def get_param_config_id(param_dict, insert_new=True):\n",
    "    try:\n",
    "        pc_index = pd.read_csv(INDEX_FILE, index_col='id')\n",
    "    except FileNotFoundError: \n",
    "        pc_index = pd.DataFrame()\n",
    "        pc_index.index.name='id'\n",
    "\n",
    "    \n",
    "    if len(pc_index) == 0:\n",
    "        new_row = pd.DataFrame(param_dict,index = [0])\n",
    "        \n",
    "    else: \n",
    "        new_row = pd.DataFrame(param_dict,index = [pc_index.index.max()+1])\n",
    "    new_row.index.name = 'id'\n",
    "    # new_row.name = 0\n",
    "    pc_index = pd.concat([pc_index,new_row],join='outer')\n",
    "\n",
    "    duplicate_rows = pc_index.duplicated(keep=False)\n",
    "    if duplicate_rows.any():\n",
    "        pcid = duplicate_rows.idxmax()\n",
    "        pc_index = pc_index.drop_duplicates()\n",
    "    else:\n",
    "        pcid = new_row.index[0]\n",
    "\n",
    "    if insert_new:\n",
    "        pc_index.to_csv(INDEX_FILE)\n",
    "        \n",
    "    return f'pcid_{str(pcid).zfill(zfill)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_run_type(list_of_value_args):\n",
    "    if 'catch_dropout' in list_of_value_args[0]:\n",
    "        return \"modded\"\n",
    "    else:\n",
    "        return \"vanilla\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'task_name': 'qnli',\n",
       " 'model_name_or_path': 'bert-base-uncased',\n",
       " 'per_device_train_batch_size': 32,\n",
       " 'per_device_eval_batch_size': 64,\n",
       " 'weight_decay': 0.01,\n",
       " 'lr_scheduler_type': 'linear',\n",
       " 'warmup_steps_fraction': 0.1,\n",
       " 'report_to': 'all',\n",
       " 'insert_dropout': 0.1,\n",
       " 'training_size': 512,\n",
       " 'beta1': 0.9,\n",
       " 'beta2': 0.999,\n",
       " 'early_stopping_patience': 100,\n",
       " 'early_stopping_min_delta': 0,\n",
       " 'original_gradient_fraction': 0,\n",
       " 'num_train_epochs': 300,\n",
       " 'learning_rate': 3e-06,\n",
       " 'evaluation_steps': 128}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "keys, values = zip(*value_args.items())\n",
    "list_of_value_args = [dict(zip(keys, v)) for v in product(*values)]\n",
    "print(len(list_of_value_args))\n",
    "list_of_value_args[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle((list_of_value_args))\n",
    "list_of_value_args = list_of_value_args[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected sweep type: vanilla\n",
      "Number of experiments in this run in the range of 10^3 (200)\n"
     ]
    }
   ],
   "source": [
    "from math import log, ceil\n",
    "sweep_type = determine_run_type(list_of_value_args)\n",
    "print(f'Detected sweep type: {sweep_type}')\n",
    "n_runs = len(list_of_value_args)*len(seeds)\n",
    "magnitude = ceil(log(n_runs,10))\n",
    "print(f'Number of experiments in this run in the range of 10^{magnitude} ({n_runs})')\n",
    "sweep_identifier = f'{GENERATION}_{str(SWEEP_ID).zfill(2)}'\n",
    "\n",
    "with open(f'instructions_{sweep_identifier}.txt','w', newline='\\n') as f:\n",
    "    sweep_identifier += f'_{sweep_type}'\n",
    "    for idx, value_args in enumerate(list_of_value_args): # Iterate over param constellations\n",
    "        value_args[\"run_generation\"] = GENERATION # set generation arg\n",
    "        param_config_id = get_param_config_id(value_args) # get pcid\n",
    "        value_args[\"param_config_id\"] = param_config_id # set pcid to args\n",
    "        for idy, seed in enumerate(seeds):\n",
    "            value_args[\"seed\"] = seed # update current seed to args\n",
    "\n",
    "            run_id = str(idx*len(seeds)+idy).zfill(magnitude)\n",
    "            output_dir = f'{base_dir}/sweep_{sweep_identifier}/run_{run_id}'\n",
    "            value_args[\"output_dir\"] = output_dir\n",
    "\n",
    "            instruction = compose_instruction(\n",
    "                value_args = value_args, \n",
    "                boolean_args = boolean_args,\n",
    "                use_accelerate = use_accelerate,\n",
    "                device=DEVICE\n",
    "            )\n",
    "\n",
    "            f.write(instruction + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_id = 0\n",
    "# run_type = 'single'\n",
    "\n",
    "\n",
    "# output_dir = f'{base_dir}/{run_name}'\n",
    "\n",
    "# value_args ={\n",
    "#     'task' : 'rte',\n",
    "#     'model_name_or_path' : 'bert-base-cased',\n",
    "#     'per_device_train_batch_size' : 32 // num_devices,\n",
    "#     'per_device_eval_batch_size' : 16 // num_devices,\n",
    "#     'learning_rate': 1e-6,\n",
    "#     'weight_decay' : 0,\n",
    "#     'num_train_epochs' : 100000,\n",
    "#     'max_train_steps' : 100000,\n",
    "#     'lr_scheduler_type' : 'linear',\n",
    "#     'num_warmup_steps' : 500,\n",
    "#     'output_dir' : output_dir,\n",
    "#     'seed' : 0,\n",
    "#     'report_to' : 'all',\n",
    "#     'insert_dropout' : 0.1,\n",
    "#     'catch_dropout' : 0,\n",
    "#     'training_size' : 32,\n",
    "#     'beta1' : 0.9,\n",
    "#     'beta2' : 0.999,\n",
    "#     'early_stopping_patience' : 5000,\n",
    "#     'early_stopping_min_delta' : 0,\n",
    "#     'original_gradient_fraction' : 0\n",
    "# }\n",
    "# boolean_args = {\n",
    "#     'with_tracking' : True,\n",
    "\n",
    "# }\n",
    "\n",
    "# # Compose instruction\n",
    "# instruction = compose_instruction(value_args = value_args, \n",
    "#                                   boolean_args = boolean_args,\n",
    "#                                   use_accelerate = use_accelerate)\n",
    "\n",
    "# print(instruction)\n",
    "# # Write instruction\n",
    "# with open(f'instruction_{GENERATION}_{run_id}.txt', 'w') as f:\n",
    "#     f.write(instruction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantastic-umbrella",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
