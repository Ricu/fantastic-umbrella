{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_instruction(task,\n",
    "                        output_dir,\n",
    "                        num_train_epochs = '3',\n",
    "                        learning_rate = '1e-5',\n",
    "                        training_size = '1',\n",
    "                        insert_dropout = '-1',\n",
    "                        catch_dropout = '-1',\n",
    "                        use_modded = False,\n",
    "                        model_name_or_path=\"bert-base-cased\",\n",
    "                        max_length = '128',\n",
    "                        per_device_train_batch_size = 32,\n",
    "                        seed = '0',\n",
    "                        lr_scheduler_type = \"linear\",\n",
    "                        num_warmup_steps = 200,\n",
    "                        early_stopping_patience=100,\n",
    "                        early_stopping_min_delta=0\n",
    "                        ):\n",
    "    \n",
    "\n",
    "    base_command = 'accelerate launch run_glue_no_trainer_modded.py '\n",
    "    per_device_train_batch_size = 16\n",
    "    # base_command = 'nohup python run_glue_no_trainer_modded.py '\n",
    "    argument_list = [\"--model_name_or_path\", model_name_or_path,\n",
    "                     \"--max_length\", max_length,\n",
    "                     \"--per_device_train_batch_size\", f'{per_device_train_batch_size}',\n",
    "                     \"--seed\", seed,\n",
    "                     \"--with_tracking\",\n",
    "                     \"--report_to\", \"all\"\n",
    "                    ]\n",
    "\n",
    "    argument_list = argument_list + [\"--lr_scheduler_type\" , f\"{lr_scheduler_type}\"]\n",
    "    argument_list = argument_list + [\"--num_warmup_steps\" , f\"{num_warmup_steps}\"]\n",
    "    argument_list = argument_list + [\"--early_stopping_patience\", f\"{early_stopping_patience}\"]\n",
    "    argument_list = argument_list + [\"--early_stopping_min_delta\", f\"{early_stopping_min_delta}\"]\n",
    "\n",
    "\n",
    "    argument_list = argument_list + [\"--task_name\", f'{task}']\n",
    "    argument_list = argument_list + [\"--num_train_epochs\", f'{num_train_epochs}']\n",
    "    argument_list = argument_list + [\"--learning_rate\", f'{learning_rate}']\n",
    "    argument_list = argument_list + [\"--training_size\", f'{training_size}']\n",
    "    argument_list = argument_list + [\"--insert_dropout\", f'{insert_dropout}']\n",
    "    argument_list = argument_list + [\"--catch_dropout\", f'{catch_dropout}']\n",
    "\n",
    "\n",
    "    if use_modded:\n",
    "        argument_list.append(\"--use_modded\")\n",
    "\n",
    "\n",
    "    argument_list = argument_list + [\"--output_dir\",output_dir]\n",
    "    argument_string = ' '.join(argument_list)\n",
    "    instruction = base_command + argument_string\n",
    "    return instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_parameters_reference = {\n",
    "    'model_name_or_path':[\"bert-base-cased\"],\n",
    "    \"task\" : ['rte'],\n",
    "    \"learning_rate\" : [1e-6,2e-7,5e-7],\n",
    "    \"insert_dropout\" : [0.1],\n",
    "    \"training_size\" : [32],\n",
    "    \"num_warmup_steps\" : [500],\n",
    "    \"use_modded\" : [False],\n",
    "    \"num_train_epochs\" : [4096]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': 'bert-base-cased',\n",
       " 'task': 'rte',\n",
       " 'learning_rate': 1e-06,\n",
       " 'insert_dropout': 0.1,\n",
       " 'training_size': 32,\n",
       " 'num_warmup_steps': 500,\n",
       " 'use_modded': False,\n",
       " 'num_train_epochs': 4096}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "keys, values = zip(*experiment_parameters_reference.items())\n",
    "permutations_dicts_reference = [dict(zip(keys, v)) for v in product(*values)]\n",
    "print(len(permutations_dicts_reference))\n",
    "permutations_dicts_reference[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fantastic-Umbrella Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_parameters_modded = {\n",
    "    'model_name_or_path':[\"bert-base-cased\"],\n",
    "    \"task\" : ['rte'],\n",
    "    \"learning_rate\" : [1e-6, 5e-7, 2e-7],\n",
    "    \"insert_dropout\" : [0.2],\n",
    "    \"catch_dropout\" : [0.0],\n",
    "    \"training_size\" : [32],\n",
    "    \"use_modded\" : [True],\n",
    "    \"num_train_epochs\" : [4096],\n",
    "    \"num_warmup_steps\" : [500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name_or_path': 'bert-base-cased',\n",
       " 'task': 'rte',\n",
       " 'learning_rate': 1e-06,\n",
       " 'insert_dropout': 0.2,\n",
       " 'catch_dropout': 0.0,\n",
       " 'training_size': 32,\n",
       " 'use_modded': True,\n",
       " 'num_train_epochs': 4096,\n",
       " 'num_warmup_steps': 500}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "keys, values = zip(*experiment_parameters_modded.items())\n",
    "permutations_dicts_modded = [dict(zip(keys, v)) for v in product(*values)]\n",
    "print(len(permutations_dicts_modded))\n",
    "permutations_dicts_modded[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = \"11a\"\n",
    "base_dir = '/home/lange/fantastic-umbrella/runs'\n",
    "\n",
    "from math import log, ceil\n",
    "# permutations_dicts_modded = []\n",
    "permutations_dicts_reference = []\n",
    "permutations_dicts = permutations_dicts_reference + permutations_dicts_modded\n",
    "magnitude = ceil(log(len(permutations_dicts),10))\n",
    "\n",
    "\n",
    "with open(f'instructions_{generation}.txt', 'w', newline='\\n') as f:\n",
    "    \n",
    "    for idx, parameters in enumerate(permutations_dicts):\n",
    "        # print(f'##################################### Current iteration: {idx} #####################################')\n",
    "        \n",
    "        run_id = str(idx).zfill(magnitude)\n",
    "        if parameters[\"use_modded\"]:\n",
    "            run_type = \"modded\"\n",
    "        else:\n",
    "            run_type = \"vanilla\"\n",
    "\n",
    "        run_name = f'run_{generation}_{run_id}_{run_type}'\n",
    "\n",
    "        output_dir = f'{base_dir}/{run_name}'\n",
    "        instruction = compose_instruction(output_dir=output_dir,\n",
    "                                          **parameters)\n",
    "        f.write(instruction + '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fantastic-umbrella",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
