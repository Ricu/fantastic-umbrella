{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":161902,"status":"ok","timestamp":1679397629926,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"_VO60aip44kg","outputId":"dfad5c6b-b277-4082-af6a-ce5e19b6380e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n","Collecting torch\n","  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Collecting nvidia-cudnn-cu11==8.5.0.96\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.0)\n","Collecting nvidia-cuda-cupti-cu11==11.7.101\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Collecting nvidia-curand-cu11==10.2.10.91\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Collecting triton==2.0.0\n","  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (63.4.3)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Collecting lit\n","  Downloading lit-16.0.0.tar.gz (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n","Building wheels for collected packages: lit\n","  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93601 sha256=f94943cd76d6d3e9159bee2200ce1af8369f0ea7ddde663583985971e4592132\n","  Stored in directory: /root/.cache/pip/wheels/c7/ee/80/1520ca86c3557f70e5504b802072f7fc3b0e2147f376b133ed\n","Successfully built lit\n","Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.1+cu116\n","    Uninstalling torch-1.13.1+cu116:\n","      Successfully uninstalled torch-1.13.1+cu116\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchvision 0.14.1+cu116 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n","torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n","fastai 2.7.11 requires torch<1.14,>=1.7, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-16.0.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 triton-2.0.0\n"]}],"source":["# !pip install torch -U"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1679397736620,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"dw8ugrCeiNfs","outputId":"fda57c3d-69b8-4234-b085-96649e39002f"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory\n","  warn(f\"Failed to load image Python extension: {e}\")\n"]},{"name":"stdout","output_type":"stream","text":["PyTorch Version:  2.0.0+cu117\n","Torchvision Version:  0.14.1+cu116\n"]}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader,TensorDataset,random_split\n","from torchvision import datasets, transforms\n","\n","import matplotlib.pyplot as plt\n","import torchvision\n","import numpy as np\n","import time, os, copy, random\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"]},{"cell_type":"markdown","metadata":{"id":"SjqoNbkwixux"},"source":["# Create artifical data"]},{"cell_type":"markdown","metadata":{"id":"JKpXRjemdI4c"},"source":["Set random seeds.\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679323445568,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"Mn7f1HwtwAJd"},"outputs":[],"source":["torch.manual_seed(0)\n","random.seed(0)\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{"id":"3YL5aah_dZVq"},"source":["Set the number of batches and the batch size. For these early tests, 2 batches of size 3 should give good insights while not being to complicated."]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":945,"status":"ok","timestamp":1679323440979,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"gA-mAFABomFA"},"outputs":[],"source":["n_batches = 5\n","batch_size = 3\n","n_samples = n_batches * batch_size"]},{"cell_type":"markdown","metadata":{"id":"Dp0I-6oqd0et"},"source":["The network architecture, initial weights and test data is similar to this source:\n","https://www.kaggle.com/code/sironghuang/understanding-pytorch-hooks.\n","\n","In the linked notebook, only one datapoint is evaluated. Here, this datapoint will be repeated to include the effects of using batches."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":201,"status":"ok","timestamp":1679323469756,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"jsDhED5Ai0Ed","outputId":"7e5b927b-63fc-4833-cd7b-95e9f078c77a"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset size :torch.Size([15, 2])\n","single sample, size: torch.Size([2]) | values: tensor([0.0500, 0.1000])\n"]}],"source":["artifical_data = torch.empty((n_samples,2))\n","artifical_data[:,0] = 0.05\n","artifical_data[:,1] = 0.1\n","print(f'dataset size :{artifical_data.shape}')\n","print(f'single sample, size: {artifical_data[0,:].shape} | values: {artifical_data[0,:]}')"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":209,"status":"ok","timestamp":1679323713187,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"vbSsuujJ7CsS","outputId":"b035d653-61a8-413e-f575-530399062c30"},"outputs":[{"name":"stdout","output_type":"stream","text":["label set size :torch.Size([15, 2])\n","single label, size: torch.Size([2]) | values: tensor([0.0100, 0.9900])\n"]}],"source":["artifical_labels = torch.empty_like(artifical_data)\n","artifical_labels[:,0] = 0.01\n","artifical_labels[:,1] = 0.99\n","print(f'label set size :{artifical_labels.shape}')\n","print(f'single label, size: {artifical_labels[0,:].shape} | values: {artifical_labels[0,:]}')"]},{"cell_type":"markdown","metadata":{"id":"d6vezV9afvvD"},"source":["Next, the datasets and dataloader are created from the tensors. The first 4*batch_size samples are being used as the training set and the remaining batch_size samples are the test set. The splitting of datasets is not necessary for now but will make extension easy later on.\n","\n","Tensordata requires a 2D tensor, where each line represents one training sample. Targets may be 1-D or 2-D."]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":263,"status":"ok","timestamp":1679324000805,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"4j4s1b5ovWul","outputId":"089fb814-c012-44d2-85ff-47932f36bb97"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of batches in the training set is 12\n"]}],"source":["train_set = TensorDataset(artifical_data[:4*batch_size,], artifical_labels[:4*batch_size,])\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n","print(f'Number of batches in the training set is {len(train_set)}')"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1679324001478,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"dvcyG4rszTr9","outputId":"8923e103-2762-4c78-cb05-c1fb557062db"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of batches in the evaluation set is 3\n"]}],"source":["eval_set = TensorDataset(artifical_data[4*batch_size:,], artifical_labels[4*batch_size:,])\n","eval_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n","print(f'Number of batches in the evaluation set is {len(eval_set)}')"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":297,"status":"ok","timestamp":1679324011989,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"rwHDPE_ezrrK"},"outputs":[],"source":["dataloaders = {'train':train_loader,\n","               'eval':eval_loader}"]},{"cell_type":"markdown","metadata":{"id":"o0iH0l_Fj7e1"},"source":["# Create sample model"]},{"cell_type":"markdown","metadata":{"id":"IAA6XFQrXyd_"},"source":["The model architecture and weights are taken from [here](https://www.kaggle.com/code/sironghuang/understanding-pytorch-hooks) for reference."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":237,"status":"ok","timestamp":1679325398762,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"8aSvRv4aj-jN"},"outputs":[],"source":["class TestModel(nn.Module):\n","  def __init__(self, dropout_rate = 0.5):\n","        super().__init__()\n","        self.fc1 = nn.Linear(2,2)\n","        self.s1 = nn.Sigmoid()\n","        self.fc2 = nn.Linear(2,2)\n","        self.s2 = nn.Sigmoid()\n","        self.fc1.weight = torch.nn.Parameter(torch.Tensor([[0.15,0.2],[0.250,0.30]]))\n","        self.fc1.bias = torch.nn.Parameter(torch.Tensor([0.35]))\n","        self.fc2.weight = torch.nn.Parameter(torch.Tensor([[0.4,0.45],[0.5,0.55]]))\n","        self.fc2.bias = torch.nn.Parameter(torch.Tensor([0.6]))\n","\n","  def forward(self, x):\n","      x = self.fc1(x)\n","      x = self.s1(x)\n","      x = self.fc2(x)\n","      x = self.s2(x)\n","      return x"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679325400694,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"QRCU-Okzm2NS","outputId":"4abc9aeb-71f3-44a4-c5e3-5bd6d35f79e6"},"outputs":[{"name":"stdout","output_type":"stream","text":["TestModel(\n","  (fc1): Linear(in_features=2, out_features=2, bias=True)\n","  (s1): Sigmoid()\n","  (fc2): Linear(in_features=2, out_features=2, bias=True)\n","  (s2): Sigmoid()\n",")\n"]}],"source":["model = TestModel()\n","print(model)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1679325402437,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"MMae-esXuBlq","outputId":"f31c7d9e-aae1-43f8-fa28-ef0002a0f1fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Layer: fc1.weight | Size: torch.Size([2, 2]) | Values : tensor([[0.1500, 0.2000],\n","        [0.2500, 0.3000]], grad_fn=<SliceBackward0>) \n","\n","Layer: fc1.bias | Size: torch.Size([1]) | Values : tensor([0.3500], grad_fn=<SliceBackward0>) \n","\n","Layer: fc2.weight | Size: torch.Size([2, 2]) | Values : tensor([[0.4000, 0.4500],\n","        [0.5000, 0.5500]], grad_fn=<SliceBackward0>) \n","\n","Layer: fc2.bias | Size: torch.Size([1]) | Values : tensor([0.6000], grad_fn=<SliceBackward0>) \n","\n"]}],"source":["for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"80KDZLJws763"},"source":["# Prepare optimizer and loss function"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1679325452522,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"EltLsz4_tYEN"},"outputs":[],"source":["sgd_parameters = {\n","    'lr':1e-3,        # undefined\n","    'momentum':0,   # 0\n","    'dampening':0,    # 0\n","    'weight_decay':0  # 0\n","}\n","optimizer = torch.optim.SGD(model.parameters(), **sgd_parameters)"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":1230,"status":"ok","timestamp":1679325464712,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"B3US8RnNthm-"},"outputs":[],"source":["loss_fn = nn.MSELoss()"]},{"cell_type":"markdown","metadata":{"id":"0Y3ssP8euFuK"},"source":["# Hooks"]},{"cell_type":"markdown","metadata":{"id":"lqcyqhszowgw"},"source":["Create two hooks for debugging purposes:\n","- the forward hook will print the input and output tensor produced during the forward pass.\n","- the backward hook will print the gradient of the output (the gradient coming from the loss) and the gradient input (the gradient used for following calculations closer to the input layers) during the backward pass. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uY2kQXSEowRP"},"outputs":[],"source":["def forward_debug_hook(module, input, output):\n","  print('forward hook')\n","  print(input)\n","  print(output)\n","\n","def backward_debug_hook(module, grad_input, grad_output):\n","   print('backward hook')\n","   print(grad_input)\n","   print(grad_output)"]},{"cell_type":"markdown","metadata":{"id":"IFVjXtIsuYNt"},"source":["# Model training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5l3DWY0euaYR"},"outputs":[],"source":["def train_model(model, dataloaders, loss_fn, optimizer, num_epochs=5):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    n_train_batches = len(dataloaders['train'])\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        ############ train phase ############\n","        phase = 'train'\n","        model.train()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for batch, (inputs, labels) in enumerate(dataloaders[phase]):\n","          optimizer.zero_grad()\n","\n","\n","          # handlef = affected_layer.register_forward_hook(forward_debug_hook)\n","          handleb = affected_layer.register_full_backward_hook(backward_debug_hook)\n","          # Get model outputs and calculate loss\n","\n","          print('*'*5 + 'forward pass' + '*'*5)\n","          outputs = model(inputs)\n","          print('outputs')\n","          print(outputs)\n","\n","          # outputs.backward(torch.tensor([[0.7414,-0.2171],[0.7414,-0.2171],[0.7414,-0.2171]],dtype=torch.float),retain_graph=True)\n","\n","          print('*'*5 + 'loss calculation' + '*'*5)\n","          loss = loss_fn(outputs, labels.float())\n","          print('loss')\n","          print(loss)\n","\n","          preds = (outputs>0.5).int()\n","          \n","\n","          # backward + optimize\n","          print('*'*5 + 'backward pass' + '*'*5)\n","          \n","          # print(affected_layer._backward_hooks)\n","          loss.backward()          \n","          print('weights grad')\n","          print(affected_layer.weight.grad)\n","          print('bias grad')\n","          print(affected_layer.bias.grad)\n","\n","          # handlef.remove()\n","          handleb.remove()\n","\n","          # print(affected_layer._backward_hooks)\n","          optimizer.step()\n","\n","          running_loss += loss.item() * inputs.size(0)\n","          running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","        ############ eval phase ############\n","        phase = 'eval'\n","        model.eval()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for batch, (inputs, labels) in enumerate(dataloaders[phase]):\n","          # disable gradient tracking for speedup\n","          with torch.set_grad_enabled(phase == 'train'):\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, labels.float())\n","            preds = (outputs>0.5).int()\n","\n","          running_loss += loss.item() * inputs.size(0)\n","          running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))  \n","\n","        val_acc_history.append(epoch_acc)\n","        print()\n","\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","\n","    return val_acc_history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kLVefwl04gyl"},"outputs":[],"source":["hist = train_model(model,\n","                   dataloaders,\n","                   loss_fn,\n","                   optimizer,\n","                   num_epochs=1\n","                   )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tsdmhXg0wgRj"},"outputs":[],"source":["print(affected_layer._backward_hooks)\n","print(catch_hook.caught_grad)\n","catch_hook.close()\n","print(affected_layer._backward_hooks)"]},{"cell_type":"markdown","metadata":{"id":"jyREiA7usUCM"},"source":["Erkenntnisse:\n","- layer.weight.grad wird erst in backward() befüllt.\n","- Im hook: gradient_out ist der bisherige **Gesamt**gradient. gradient_in ist  gradient_out*dgradient_out/dgradient_in.\n","- Der gradient für z.B. weight wird berechnet durch entsprechendes summe_batch(gradient_out*dgradient_out/dgewicht).\n","- um also den zur Idee passenden gradienten abzufangen, nutze einen full_backward_hook auf der passenden layer (hier z.B. fc2) und extrahiere den gradient_out.\n","- das wiedereinsetzen sollte ebenfalls durch einen hook funktionieren\n"]},{"cell_type":"markdown","metadata":{"id":"CJhpHOt4tEjV"},"source":["# Miscellanous code\n","This is mostly code that was used to comprehend and retrace what is happening under the hood."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bGldXZWefqqv"},"outputs":[],"source":["# artifical_labels = torch.randint(low=0,high=2,size=(n_samples,1))\n","# artifical_labels_batch = artifical_labels[0:batch_size]\n","# print(artifical_labels_batch.shape)\n","# print(artifical_labels_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AnwHZYbDfYNp"},"outputs":[],"source":["# all points inside the unit-sphere with radius 0.7 are marked as 1\n","# artifical_labels = ((artifical_data[:,0]**2 + artifical_data[:,1]**2) < 0.7).int().unsqueeze(1)\n","artifical_labels = torch.empty_like(artifical_data)\n","artifical_labels[:,0] = 0.01\n","artifical_labels[:,1] = 0.99\n","\n","artifical_labels_batch = artifical_labels[0:batch_size,]\n","print(artifical_labels_batch.shape)\n","print(artifical_labels_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D7u0nvUbm9w8"},"outputs":[],"source":["model.eval()\n","output = model(artifical_data_sample)\n","print(output.shape)\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fIrdtkvpn63q"},"outputs":[],"source":["output_batch = model(artifical_data_batch)\n","print(output_batch.shape)\n","print(output_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Wxuzr7jpKYV"},"outputs":[],"source":["for name, parameter in model.linear_relu_stack.named_parameters():\n","  print(name)\n","  print(parameter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P6EZSxjRprdE"},"outputs":[],"source":["input = artifical_data_sample = artifical_data_batch[:2,:]\n","print(input)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"275NyE9hqL0L"},"outputs":[],"source":["after0 = model.linear_relu_stack[0](input)\n","# = print(torch.matmul(model.linear_relu_stack[0].weight,input.t())+model.linear_relu_stack[0].bias)\n","after0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dNXYjanTq9ys"},"outputs":[],"source":["after1 = model.linear_relu_stack[1](after0)\n","after1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2sFL71OIrmdT"},"outputs":[],"source":["after2 = model.linear_relu_stack[2](after1)\n","after2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bBfMWn_JsNMT"},"outputs":[],"source":["after3 = model.linear_relu_stack[3](after2)\n","after3"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"59tXF250sUoo"},"outputs":[],"source":["after4 = model.linear_relu_stack[4](after3)\n","after4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8YIBqksLsXlm"},"outputs":[],"source":["after5 = model.linear_relu_stack[5](after4)\n","after5"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOImYbk/2LoZEs2wIKbjx2n","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
