{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMvR4qocDV+r7KG6rAIW8Nk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mzy6PgDdnGhD","executionInfo":{"status":"ok","timestamp":1679657339027,"user_tz":-60,"elapsed":6614,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"73bacfcf-478e-431b-d5d3-be6b9d6adfa3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (2.0.0)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.15.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch) (2.0.0)\n","Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.4.91)\n","Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.101)\n","Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/dist-packages (from torch) (10.9.0.58)\n","Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/dist-packages (from torch) (10.2.10.91)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/dist-packages (from torch) (2.14.3)\n","Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/dist-packages (from torch) (11.4.0.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/dist-packages (from torch) (8.5.0.96)\n","Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.91)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/dist-packages (from torch) (11.7.99)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/dist-packages (from torch) (11.10.3.66)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.0)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.40.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.6.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch) (3.25.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch) (1.3.0)\n"]}],"source":["!pip install torch torchvision -U"]},{"cell_type":"code","source":["!pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FgQB_5gq61R5","executionInfo":{"status":"ok","timestamp":1679918101320,"user_tz":-120,"elapsed":26797,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"b2c7083a-549c-4206-eecc-26c1593eaba3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.13.3-py3-none-any.whl (199 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.13.3 tokenizers-0.13.2 transformers-4.27.3\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader,TensorDataset,random_split\n","from torchvision import datasets, transforms\n","\n","import matplotlib.pyplot as plt\n","import torchvision\n","import numpy as np\n","import time, os, copy, random\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_cxOd0GInK8-","executionInfo":{"status":"ok","timestamp":1679657339028,"user_tz":-60,"elapsed":55,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"985f19af-50dc-45fb-dc93-db82156ee803"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch Version:  2.0.0+cu117\n","Torchvision Version:  0.15.1+cu117\n"]}]},{"cell_type":"markdown","source":["# Create artifical data\n","Set random seeds."],"metadata":{"id":"C6BQosG8nVr0"}},{"cell_type":"code","source":["torch.manual_seed(0)\n","random.seed(0)\n","np.random.seed(0)"],"metadata":{"id":"2m2NOgXinVW6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Set the number of batches and the batch size. For these early tests, 5 batches of size 3 should give good insights while not being to complicated."],"metadata":{"id":"tvP3-0sNneP3"}},{"cell_type":"code","source":["n_batches = 10\n","n_train_batches = 7\n","batch_size = 4\n","n_samples = n_batches * batch_size"],"metadata":{"id":"DlsoVzXZncok"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The network architecture, initial weights is similar to this source:\n","https://www.kaggle.com/code/sironghuang/understanding-pytorch-hooks.\n","\n","In the linked notebook, only one datapoint is evaluated. Here, this datapoint will be repeated to include the effects of using batches."],"metadata":{"id":"n3IIHJwinuDQ"}},{"cell_type":"code","source":["artifical_data = torch.rand(size=(n_samples,2))\n","print(f'dataset size :{artifical_data.shape}')\n","print(f'single sample, size: {artifical_data[0,:].shape} | values: {artifical_data[0,:]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w99qdOconwbW","executionInfo":{"status":"ok","timestamp":1679657339030,"user_tz":-60,"elapsed":33,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"42a34870-ccbc-4913-8333-0ea40666978e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dataset size :torch.Size([40, 2])\n","single sample, size: torch.Size([2]) | values: tensor([0.4963, 0.7682])\n"]}]},{"cell_type":"code","source":["artifical_labels = ((artifical_data[:,0]**2 + artifical_data[:,1]**2) < 0.7).int().unsqueeze(1)\n","print(f'label set size :{artifical_labels.shape}')\n","print(f'single label, size: {artifical_labels[0,:].shape} | values: {artifical_labels[0,:]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XCo6Vu-oaJR","executionInfo":{"status":"ok","timestamp":1679657339031,"user_tz":-60,"elapsed":25,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"907cb294-0378-4949-cc1c-48ef4bbaa7bc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["label set size :torch.Size([40, 1])\n","single label, size: torch.Size([1]) | values: tensor([0], dtype=torch.int32)\n"]}]},{"cell_type":"code","source":["plt.scatter(artifical_data[:,0],artifical_data[:,1],c=artifical_labels[:,0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"zYLohpewohDl","executionInfo":{"status":"ok","timestamp":1679657339577,"user_tz":-60,"elapsed":563,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"c3c501fa-c5a5-40c9-8142-4669aa936e1e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.collections.PathCollection at 0x7fb8b19f4d00>"]},"metadata":{},"execution_count":72},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAAAm0ElEQVR4nO3deXhcZdnH8e89k5nJZGlpm7ZAV5ayI1vYKgIKyL4JlsILiKBVBEURFNwQUFFWdxYVRGVHXiwvS2UVZJMCZStboZYWCi1taJsmsyRzv39MgDSZNNN0Zs7M5Pe5rl7NPOd0zq8nyZ2T5zzneczdERGRyhcKOoCIiBSGCrqISJVQQRcRqRIq6CIiVUIFXUSkStQEdeCmpiafOHFiUIcXEalITz/99PvuPjLXtsAK+sSJE5k5c2ZQhxcRqUhmNq+vbepyERGpEiroIiJVQgVdRKRKqKCLiFSJfgu6mV1tZovM7MU+tpuZ/drM5pjZ82a2feFjioj05u68+fw8Xnz0FVKJVNBxApfPKJc/A78F/tLH9v2BSV1/dgYu7/pbRKRo3p6zkO8feAFL3llKKBzCM85pV0xjr2M+FXS0wPR7he7uDwNLV7PLocBfPOsJYB0zW69QAUVEespkMnxn7/N4Z867JFYmaVveTntrgsumXcGbz/c5qq/qFaIPfQwwv9vrBV1tIiJF8eK/X2FFSys9p/9OJzuY/vsZAaUKXkkfLDKzacA0gPHjx5fy0CJSBTo7Orn7Tw9wyyXTSaxM9tqe6cyw9N2WAJKVh0IU9LeBcd1ej+1q68XdrwKuAmhubtbKGiKSN3fnx0dcxLP3v0iyrXcxB6itj7HLQc0lTlY+CtHlMh04vmu0yy7AMndfWID3FRH5yMtPvs6sB/ou5rF4lHU3GMVe/7NbiZOVj36v0M3sBmBPoMnMFgDnABEAd78CuAs4AJgDtAFfLFZYERm8XnzkZdLJjpzbRowZxpHfOpgDv7IPsXisxMnKR78F3d2P7me7A6cULJGISA7DRq9DpDZCZ2vnKu2xeJRjzj6CQ762b0DJyoeeFBWRirDb53YiHO5dskLhEHtOnRxAovKjgi4iFSHeEOei+89h1IQmautj1DbEaBoznJ/P+AFDhjcGHa8sBDYfuojImpq0/Yb87c3fM2/2AjyTYcKW4wiFdF36IRV0EakoZsbELcf1v2NA2la0c+uld/DQTY8Ri0c5+OR92e/ET5fkB48KuohIgaQSKb6+y9m8O3cRqUQagMu/dQ0v/PtlvvvnU4t+fP2uUubef2cpt//mbm655A4WvPZOSY/99pyFnHP4hRwy9Himjp3G9RfcRmdHZ///UGSQeuimx1j01vsfFXOAxMokD9/8WEm+f3WFXsbuv/4RLv3S5WBGpjPDn394A0d99zCOP2dK0Y+9ZGELp+50NiuXt+EZp31FO9f/9O/Mf/WdklxpiFSiZx94IeeUBKGaMLMff42xm6xf1OPrCr1MLXt/OZd+6XJSiTSp9hQdqQ5SiTQ3X/QPXn/mzaIf//bf3EWyPYlnPp6hIdmW4uGbH2PR/PeLfnyRSjR6wkhqor2vk81gxPrDin58FfQy9cT/PU0ox5jbdCLNgzf+u+jHn/34azmfyovEIsx7aX6OfyGV7u05C7nl4unc9ss7WfTWYgBWLm/jqRmzeOmxV8lkMgEnLH/7n7QXNTXhVdpCIaNhnXq2/cxWRT++ulzKVPcr41XaAS/BtGYTtxzHS4++2qvPPJ3qYL0NRxc/gJTUDRfcxt/Ov5VMxjEz/vS969jtiJ159Lb/EI6EcXcahtZzwT3fZ8IW5TvCJGijJ4zkvOnf5efH/Zq25e1kMs64TdfnnL+fQTgc7v8N1pL1nE+4VJqbm33mzJmBHLsStCxaxrETT17l5gpArC7GxQ+cw2Y7TSrq8d+es5CvbnfmKv2BkViErXbbjAvv/VFRjy2lNW/2fE7Z8SyS7f0v4TZi/WFcN+/ykhSnSpbJZFjw2kJi8SijJ4ws6Hub2dPunnNKSXW5lKlho4Zy6m9PIhqPUhOtIRQOEYtHOfSUfYtezAHGbLweP5/xQyZsOY5wTYhILMIeR03m3P89s+jHltJ6+NYn6EjnnvSqp7YVCV585JUiJ6p8oVCI8ZuNKXgx74+6XMrY/ifuxXaf2ZqHb3mcdKqDXQ9uZsNPTCjZ8becvCl/fOFS2lvbicQi1ESq/8tlwWvvMP3yGbw3bzE77L0N+3xhD+L1tUHHKip3z7sbzwxWtLQWN5AMmLpcRLr85+5nOe/zF9OR6qSzo5NYXZQR6w3jt//5OY3DGoKOVzRzX3yLU3c+m1QeXS7R2gg3zL+SISM0d0pQ1OUi0o/Ozk4uOuG3JNtSH90ITralWLxgCbdcPD3gdMW1wVbjOfqsw4jGo4QjYWqiNURiNYwa30SsLju3uBnE6qIc/+MpKuZlrPp/hxbJw4LXFpJo632Fmk528Mjfn+TEnx4TQKrSOfaHn2f3z0/msdv/Q7gmzG5H7MyI9YZx398e4eFbHqNheAMHf/WzbLPHlkFHldVQQZeytXLZSsKRGmrrir8CTbyhlkxn7mkN6oZUdx/6h8ZvNobxZx2+StsBX9qLA760V0CJZE2py0XKzpxZc/nKdmdwxKiTOHzYF/j+QT+jZdGyoh5z1LgmNvjEhF4Pc9XWxzjs1AOKemyRQlFBl7LS8t4HfHvPc3jzuXl0pjvpSHfy9L3Pc8anz6HYN/DPufUM1ttwFPHGWuqGxInWRtjn+D3Y+7jdi3pckUJRl4uUlXuufoCO1KpjojvTnSxesITnH55d1D7ckWNHcM0rv+alx15lyTstbL7zxowaX9pxxCJrQwVdyspbr7zd6+lYyE6F8O7cRUW/KWdmbPXJzYp6DJFiUZeLlJUtdt2U2vreN0HdYaNtJ5Y+kEgFUUGXsrL3sZ+iYVg94W4z1kXjUbb+1GZsvO0GASYTKX8q6FJW4g1xfv/UL9j7uN0ZMqKREesPZ8qZh3Du7d8NOppI2VMfupSdYaPX4Yw/fS3oGCIVR1foIiJVQgVdRKRKqKCLiFQJFXQRkSqhgi4iUiVU0EVEqoQKuohIlciroJvZfmb2qpnNMbOzcmwfb2YPmtmzZva8mWm+UZEKl8lkuO1Xd3LchqfwuREn8JOpl7Fw7ntBx5LV6HdNUTMLA68B+wALgKeAo919drd9rgKedffLzWwL4C53n7i699WaoiLl7ZdfvZL7/vYIybYkAKGQUTe0jj+9dBnD1x0WaDZ356VHX+G5h2YzpKmRPY+aXNXrvna3tmuK7gTMcfc33T0F3Agc2mMfB4Z0fTwUeGegYUUkeEsWtvDPa//1UTEHyGScZFuS//31XQEmg86OTn502IWcvf9PufbHN3HlGddyzISTefHfLweaqxzkU9DHAPO7vV7Q1dbdj4FjzWwBcBfw9YKkE5FA/PfFt4jWRnq1p5MdvPjoqwEk+th9f3uYWQ+8QGJlEs84ybYUidYE5x55CZ19LCM4WBTqpujRwJ/dfSxwAPBXM+v13mY2zcxmmtnMxYsXF+jQIlJooyeOIt1joRGAcE2I8ZutH0Cij8245kESK5O92pPtSeY8MzeAROUjn4L+NjCu2+uxXW3dnQTcDODujwO1QFPPN3L3q9y92d2bR47USjAi5WrspPXYYtdNiMRWnb8vEo3wuW8eFFCqPJgFnSBQ+RT0p4BJZraBmUWBqcD0Hvu8BewFYGabky3ougSXitXZ2clTM2ZxzzUPMm/2/P7/QRU693+/w26H70wkVkNNtIb1N1qX86Z/lwmbjw00175f/HTORVBq62JsvN3E0gcqI/1On+vuHWZ2KjADCANXu/tLZnYeMNPdpwPfBv5gZt8ie4P0BC/2ir4iRfLufxdx+h4/ovWDNjyTIZNxJh/SzFl/+wbhcLj/N6gSdY1xvnf9N0m2J0m2pWgc3oCVwRXw3sftzqO3/4dn73+BVCJNtDaChYwf3XrGoPr85NLvsMVi0bBFKVen7Phd5jw7l0zm4++N2roY0y46joNP3jfAZPIhd2f246/x3EMvMbSpkT2mTKZhnfqgY5XE6oYtaoELkW7ef3sJc1+av0oxB0i0Jbnjin+qoJcJM2PLyZuy5eRNg45SVvTov0g3qUSaUCh3t0KqPVXiNCJrRgVdpJv1NhzNkBGNvdojsQh7HDU5gETlr7Ozkw8WL6Mj3XuYo5SWCrpIN2bGWX/9BrX1MSKx7IM1tfUx1t1gFFPO7PmAtNz26zs5YuSJHDP+ZD7X9EX+ev4taDxEcNSHLtLDJ3bfgmte+RV3X/0A785dxLZ7bsUeU3YlWhsNOlpZmfHnB7n6ezd8ND1AOpnm5l/8g2gswlHfOSzYcIOURrmIyIAct9EpvDt3Ua/2hmH13Pb+NWUxxLEare3kXCIivSx5Z2nO9pXL2tSfHhAVdBEZkPF9PDE6cuwIItHeE3tJ8amgi8iAfOXi44nFV72vEKuL8pWLjw8okaigi8iAbPeZrfnZ3d9ni8mb0rBOPZO235Af3XIGux+5a9DRBi3dFBURqSB69F9Eimb50hXc/cf7mf3Ea2yw5TgOOnlfmtYfHnSsQUkFXUQG7L15izllx7NoX5kg1Z7iqbtncduv7+bSh85l4+02CDreoKM+dBEZsCvP/Asrlq74aJ6bdDJN+4p2Lp12RcDJBicVdBEZsJkzZvWamRLgjVn/JdHWe5k4KS4VdBEZsFi898pBAKFwiJrI4F5sIggq6CIyYAd+ea9eY9Ej0Rp2O3wnaiK6RVdqKugiMmD/88Mj2fYzWxGNR6lrjFNbH2PDbSdy2uXTgo42KOlHqIgMWCQa4Sd3nM28lxcw9/l5rL/xumyyw0ZBxxq0VNBFZK1N2HwsE/qY20VKR10uIiJVQlfoZczTr0H6OQiPgugnMdOnS0T6pgpRhtw78A9Oh+RDgIGFwBph+HVYzbig44lImVKXSxnythsg+S8gAbSDr4TMIvyD04KOJiJlTAW9HLXfCLT3aMxAx+t453tBJBKRCqAul3LkfT0ybavZVqwoT+CtF0PHHAiPwRpOw2o/W9IMa8vTr+CJO8E7sdp9seg2QUcSKQpdoZej2gOAHCvMh4ZDuHR96J58HG+ZBunnwduyvyF8cAaZtttLlmFtZVqvxJdMgZV/gLY/4UuPI7P8gqBjiRSFCnoZsvpp2cJtdV0tUbA6bJ2LS7qSuq+4kGw/fncJaL2IoBZGWRPeMR9af0v2/5ABPPtx2w14enaw4USKQF0uZchCDdD0D0jcjaeehPBYLH4EFh5d2iAdb+RuzywlWyTjpUyz5pIP9rEhhSfuxSJbDPit3Tuy5yc0BAuvN+D3ESkkFfQyZRaF+KFY/NDgQoTXg865vdutDsg9y15ZsQi5fwkNAQNflT7Tfg8s/yHQAd6BR7bE1vkNFh454PcUKQR1uUjfGr4B1K7aZnGo/wpmFfClE9uHbFdLT2EsfsCA3tLTs2HZd8CXZYeTkoT0c3jLiRXRDSXVrQK+KyUoofiBMOQHYMOAGrAGqD8Zq/9y0NHyYuEmGHoBEMv+ICIORKHxLKxm4oDe09uuBVI9Wjuh8y3oeGWt8oqsrby6XMxsP+BXQBj4o7v/PMc+U4Afk73z9Jy7H1PAnBKQUN0UPH5k9mrU6jCrrEULQvGD8NhkSDwAdELs01h41MDfsGMhfV31k1kMbD7w9xZZS/0WdMt+B/8O2AdYADxlZtPdfXa3fSYBZwOfdPcWM1uL7xgpN/bh1AMVykLDoe7IwrxZ7JOQfhbo8TyApyCyVWGOITJA+XS57ATMcfc33T0F3Aj0vFP3ZeB37t4C4O6LChtTpDxY3dEQGsYqN1UtDnVfzP7gEAlQPl0uY4D53V4vAHbusc8mAGb2KNlumR+7+z0FSShSRiw0BJr+ga/8EyTuhdA6WP0XIbZv0NFECjZssQaYBOwJjAUeNrOt3f2D7juZ2TRgGsD48eMLdGiR0rLQMKzxDGg8I+goIqvIp8vlbaD78+Zju9q6WwBMd/e0u88FXiNb4Ffh7le5e7O7N48cqTG7IiKFlE9BfwqYZGYbmFkUmApM77HP7WSvzjGzJrJdMG8WLqaIBGXB6wt58s6nWThXM32Wu367XNy9w8xOBWaQ7R+/2t1fMrPzgJnuPr1r22fNbDbQCZzp7kuKGVxEiivRluS8Iy/muX/NJhINk052sPNBO3D2375BJDrwJ22leCyop9uam5t95syZgRxbRPr3y5Ov4t5rHyKVSH/UFo1HOeJbB3LiT/SYSVDM7Gl3b861TU+KSsVxz+CpZ/Hkv/DM8qDjVCV371XMAVLtKe688t6AUkl/NDmXVBTveBNfemJ2LhUMPI03nkmo/vigo1WVTGeGdLIj57b21tIusiL50xW6VAz3DL70i5BZmJ2KwFuBJKy4BE89E3S8qhKuCbNJ84a92s1gmz0GPu2wFJcKulSO9Czw5WSnC+ougbddF0Cg6nba5dOIN9RSE8n+Ih+J1hBvjPPVy04INpj0SV0uUjl8OZBrxSaHTEup01S9SdtvyFXPX8Ltv7mLN2bNY9MdN+Kwr+9P05gRQUeTPqigS+WIbA+ezrEhrkfvi2TdiaP46iUnBB1D8qQuF6kYFhrS9bh9nI+v1ONQMxGrOyy4YCJlQlfosgp3h47Z4G0Q+QRm5bXUXKj+C3hkq2yfeeYDiH0Wqzu87HKKBEEFXT7iHXPwpV8GbyH7y5vjQ35GKL5/0NFWYdEdsOgOQccQKTvqchEgu4q9Lz0eMu9kr869NTs0cNl38Y43go4nInlQQZes1OPg7fQeEpjG224KIpGIrCEVdMnKfNDHhs6utTJFpNypoEtWdMc+hgTWYbHPlDyOiKw5FXQBwMLrQt3xZIcEfqgWajaCWo3xFqkEGuUiH7HGMyG6Y3ZIoK+E2gOxus+TXddERMqdCvog5d6Bt90K7bdkG+Kfw+qmYLWfxmo/HWw4ERkQFfRByN3xlpMh9R+gPdu4Yg6evBeGXYNZrvlSRKTcqQ99MEo/A+luxRyyH6dnQeqJgEKJyNpSQR+MUjPBU73bvR3SWhZQpFKpoA9GoSYg19wntV3bRKQSqaAPRrX7guX41FsIag8ofR4RKQgV9EHIQg3Y8GshtB5YHKwOQqOxYddgoaFBxxORAdIol0HKIlvDyIeg43XAoWYSluuqXUQqhgr6IGZmENkk6BgiUiAq6CISqOVLV3D/dY/w3rzFbDl5MyYf0ky4Jhx0rIqkgi4igXnt6Tc4c69z6Ux3kmxPcddV97HeRqP55SPnE2+I9/8Gsgp1mopIINydnx3zS9qWt5Nszz4X0d6aYMGr73DTRdMDTleZVNBFJBCL57/P4vlLerWnEmkeuO6RABJVPhV0EQlEqCaM91wgq4v60AdGBV1EAtG0/nDGbzGm12RwsXiU/U/SoioDoYIuIoH5wY2nM3TkEOoaa4nEaqitj7HVbptx+Gl6YnkgNMpFisI9lZ250dshuoueQJWcxk5aj+vfupwn7niaxQuWsNnOk9h850mawnmA8iroZrYf8CsgDPzR3X/ex35HALcCO7q7pu0bpDz1HN7yJaCzqyGNN36PUP3RgeaS8hSJRvjUEbsEHaMq9NvlYmZh4HfA/sAWwNFmtkWO/RqB04AnCx1SKod7Cm85CXwZeGv2D0lYcQGefjnoeCJVLZ8+9J2AOe7+prungBuBQ3Psdz7wCyBRwHxSaZL/5qMr81WkskveiUjR5FPQxwDzu71e0NX2ETPbHhjn7ncWMJtUIl9J7rFoGfAVJY8jMpis9SgXy07Rdynw7Tz2nWZmM81s5uLFi9f20FKOorsAHTk21GG1+5Q6jcigkk9BfxsY1+312K62DzUCWwEPmdl/gV2A6WbW3PON3P0qd2929+aRI0cOPHUVcU/h7XeQWX4B3nYDnqnsq1gLj4SGbwBxoGukgtVBdAeIaWyxSDHlM8rlKWCSmW1AtpBPBY75cKO7LwM+WrfMzB4CztAol/55pgVf8nnIvA/ehlscVlwKI27EajYKOt6AhRqm4dGd8PabILMSix8AsX3I3l8XkWLpt6C7e4eZnQrMIDts8Wp3f8nMzgNmurtm0RkgX3EZdL7DR10U3g4k8GVnYSNuCTLaWrPotlh026BjiAwqeY1Dd/e7gLt6tP2oj333XPtYg0TiHnr3NzukX8IzrVioIYhUIlKh9Oh/kGw1P0/VPSEia0gFPUjxw4BYj8YwRHfETJP7i8iaUUEPkDV8HSKbZ0eBEAWrh9BobOgvgo4mIhVIk3MFyCwOw2+C9ExIvwzhsRDbHVtdV4yISB9UOQJmZhDdMftHRGQtqMtFRKRKqKCLiFQJFXQRkSqhgp4HTzxAZvEBZN7dmszi/fHEfUFHEhHpRQW9H5n2e/EPvgmdc4AkdL6Bf3A6mfZ7go4mIrIKFfT+tF5I7zU7El3tIiLlQwW9P53z+2hfgOdcyEFEJBgq6P0JjeqzXSuTi0g5UUHvT8NpZBdr6C4ODV8PIo2ISJ/0pGg/QnVHkPE0rPwVZFrAhkLDN7D4lKCjiYisQgU9D6H6qXjdUUASiK1RV4unX8NbL4HULAiPxOq/isUPKlZUERnEVNDzlC3itWv0b7xjDr50StdKRA4dLfiy7+OZ9wjVn1SUnCIyeKkPvYi89bfgCaD7aJh2aP0NmfTLeOIePP1KUPFEpMroCr2YUrOATO92T8CSz+MWBe/AI1thw/6AhepLnVBEqoiu0IupZlwfGzJACrwVSED6eXzFT0oYTESqkQp6EVn9yeTX756C9jtwz3E1LyKSJxX0IrLYZBj6UwgNJ7t2aIy+T3kHObtnRETypIJeZKH4wdjIx7CRD2Cjn4Lo7uQ87ZFttPSciKwVVZAC8I438JV/gc55EN0JqzsGMsvw9tsgswyr3ROiu2MWgiE/wJcc0TX6JUl2cegINuTcgP8XsqbcE/iKS6D97+BJiO6MDfkhVrNB0NFkkLKgJphqbm72mTNnBnLsQvLko3jL14AU0Em2WyUCpLted4DVQWQHbNiVmNXgmaV42w2QfgFqNsPqjsbCowP8X8hAZJaeCKmnyP5gBjCwRqxpBhYeEWQ0qWJm9rS7N+fapiv0teDu+LLvAe3dWpN8/A3+4Y5tkJoJibshfjAWGo41nFLCpFJonn49+zld5XPt4Em8/UZ9fiUQ6kNfG5n3ILM0z53b8fY7ihpHSqhzDlg4x4YkpF8seRwRUEFfO1bHGo1MsVjRokiJhTcE78yxIQo1W5Q8jgiooK8VCw2B6GTy6rmyOFanGRqrhUU2hcgngGj3VrAoVjc1qFgyyKmgryVb58KuK7I4WAMQhdje2Y+tPttODOJHQ3S3YMNKQdmwqyB+GNkb4QaRZmz4TVh4ZMDJZLDSTdG1ZKFhWNOt2Um2OhdCZHMsvC7uCUg+CJnlEN0VqxkfdFQpMAvVYUN/gg85H/DssFQpC++/s5TWlpWM23R9wjW57nVUJxX0ArHIZhDZ7OPXVgu1+weYSEolO7WyliMsBy2LlnH+lEt55cnXqYmECUfCfPPyaewxZXLQ0Uoir0sKM9vPzF41szlmdlaO7aeb2Wwze97M7jezCYWPKiKyej846AJmP/4q6WSa9tYErS0ruejE3/Ha028EHa0k+i3oZhYGfgfsD2wBHG1mPW/jPws0u/sngFuBCwsdVERkdebNns+82fPpTK86+iiVSPP3y+4MKFVp5XOFvhMwx93fdPcUcCNwaPcd3P1Bd2/revkEMLawMUUqi7vjqefwthvw5MN4ziGOUkhLFn5ATaR3L7JnnEVvLQ4gUenl04c+Bpjf7fUCYOfV7H8ScHeuDWY2DZgGMH68bhJKdXJP4i3TuhY48ewDSKFhMPwGTfFQRBtvN5FUIt2rPVobYYfPbhNAotIr6G15MzsWaAYuyrXd3a9y92Z3bx45UkO7pDp565WQeobslBAJ8JXQuRBf9p2go1W1IcMb+fyZh1Bb//EDfDXRGhqHN3DI1/YNMFnp5HOF/jbQfemdsV1tqzCzvYHvA3u4e7LndpFBo/0Wes3nQyeknsIzrVioIYhUg8IJ5x7FRp+YwN8v+z+WL1nBzgfuwNSzDmPI8Mago5VEPgX9KWCSmW1AtpBPBY7pvoOZbQdcCezn7osKnrKLp1/H266DzEKIfgqLH651OKUMdaxmm/rSi8nM2P3IXdn9yF2DjhKIfrtc3L0DOBWYAbwM3OzuL5nZeWZ2SNduFwENwC1mNsvMphc6qCfuy84j3n5T9oGdFRfiSw7DMysKfSiRtRP7LDmvlWo2xkJDSx5HBo+KmA/dvQNftCv4sh5bolD/FUKNXy98QJEB8kxL9uIjszQ7dTK12UVMhl+XfQBNZC1U/nzoHa+T+9fYVHaOcRV0KSMWGgZNd0PiLjw1C8ITsbrDsu0iRVQZBd0awPvolwwNKW0WkTyYxSB+OBY/POgoMohUxGxCVjMOajamd9w4VndcEJFERMpORRR0ABv2ewiPyy4qYfVADOqmQu0BQUcTESkLldHlAlh4PWj6J6RnQWYxRLYp6FN33vk+WFj9nCJSsSqmoEPXNKXR7Qr6np6ejX9wBnS+BTge2Rpb5xIsPKagxxERKbaK6XIpBs+04EuPzS74SwpIQ3oWvuRovK+bsCIiZWpwF/T2f+QYPZMBXwHJRwLJJCIyUIO6oNMxD0j0bvcO6FxQ8jgi3XmmVU9CyxoZ1AXdojtkR830Eupa0V2k9LzzbTJL/gdftBO+aGcyS47EO94MOpZUgEFd0Kn9LIRGA9HujRDdVgVdAuGewpccBemnyT4d3QHpF/AlU/HMyqDjSZkb1AXdLIqNuAXq/idb2ENjoeGr2LA/dC38K1JiyQez86eT6dbo4ElIDI5l1GTgKmrYYjFYaAg25GwYcnbQUUSy925yLifQjnfOR5cZsjqD+gpdpOzUbA4W7d1udVhky9LnkYqigi5STqK7QHgjVr2vE4HQuhDbK6hUUiFU0EXKiFkIG/5XqP8ChJrAhkPdVGzEzZhFgo4nZW7Q96GLlBsL1WGNZ0LjmUFHkQqjK3QRkSqhK3SRMuaZZZC4D0hCdHesZmzQkaSMqaCLlClPPIh/8E3AyI5LvwBvOJlQw9eCDSZlS10uImXIM61dxbwdaCM751ASWq/A0y8Emk3Klwq6SDlK/gss17dnCm+7vdRppEKooIuUpQ5wz9GeITt3v0hvKugi5Sj2KbKTc/Vgcaz2wJLHkcqggi5Shiw0HIb8EIiRHbtgQDy7KHp052DDyYC4O8/c9zzX/+w2/nntQ7SvzLEWw1rSKJci8M538fa/Q+d7WGwyxPbSU36yWu6Ot90MbdeAL4foJ7HGb0HTdLz9DvB2rHZviGyvmUArUCqR4jv7nMcbz80j1ZYkWhfjim9fy6X/Oo+JW44r2HFU0AvMk4/hLScDnUAKT0yH8IYw4nrMaoOOJ2XKV/wM2m8Gb882JO7Ak//Cmu4i1PiNYMPJWrv1sv/j9WfmkmrP3v9ItCZIGvxk6mX88YVLC3YcdbkUkHsnvux0skPNum5ceRt0zMFXXhdkNCljnlkKbTd8XMyB7Nq2bXjbtYHlksL5558f/KiYf8gdFr7xLosXLCnYcVTQC6nj1T7msk5AYnrJ40iFSL8CFsuxIQWp/5Q8jhRBrgFLH27KOZppYFTQC8mi4Jk+tqm7RfoQXh88nWNDCGomljqNFME+X9iDaLz3fbT1NhzNqHFNBTuOCnohhTeC8Gjoua6MxbG6qYFEkvJnNRO71rDt+Q0fw+pODCCRFNqRpx/MRttMJN5QCwa19TEahtXz/Ru+WdDjWCEv99dEc3Ozz5w5M5BjF5N3zMGXHAskwTuzjbX7YkN/geV88k8EPLMCX3YWJB8CQhAahg09H4vtEXQ0KZBMJsMz973AK0++TtOY4ewxZVfiDfE1fh8ze9rdm3Nuy6egm9l+wK+AMPBHd/95j+0x4C/ADsAS4Ch3/+/q3rNaCzpkV24n+TBk3odoM1azcdCRpEJ4pjW7SHRolIYnSk6rK+j9Dls0szDwO2AfYAHwlJlNd/fZ3XY7CWhx943NbCrwC+CotY9emcyiULt30DGkAlmoAWgIOoZUqHz6AHYC5rj7m+6eAm4EDu2xz6HAh+OrbgX2Ml1eiIiUVD4FfQwwv9vrBV1tOfdx9w5gGTCi5xuZ2TQzm2lmMxcvXjywxCIiklNJ79K5+1Xu3uzuzSNHjizloUVEql4+Bf1toPtkA2O72nLuY2Y1wFCyN0dFRKRE8inoTwGTzGwDM4sCU4Gejz1OB77Q9fGRwAMe1HhIEZFBKt9hiwcAvyQ7bPFqd/+pmZ0HzHT36ZaddeqvwHbAUmCqu7/Zz3suBuatZpcm4P28/hfVS+cgS+dB5+BDOg8wwd1z9lkH9mBRf8xsZl9jLQcLnYMsnQedgw/pPKyeHl0UEakSKugiIlWinAv6VUEHKAM6B1k6DzoHH9J5WI2y7UMXEZE1U85X6CIisgZU0EVEqkTgBd3M9jOzV81sjpmdlWN7zMxu6tr+pJlNDCBmUeVxDk43s9lm9ryZ3W9mE4LIWWz9nYdu+x1hZm5mVTd8LZ9zYGZTur4eXjKz60udsdjy+H4Yb2YPmtmzXd8TBwSRsyy5e2B/yD6o9AawIRAFngO26LHP14Aruj6eCtwUZOaAzsGngbquj0+utnOQ73no2q8ReBh4AmgOOncAXwuTgGeBYV2vRwWdO4BzcBVwctfHWwD/DTp3ufwJ+gpdU/PmcQ7c/UF3b+t6+QTZ+XSqTT5fCwDnk51vP1HKcCWSzzn4MvA7d28BcPdFJc5YbPmcAweGdH08FHinhPnKWtAFvWBT81awfM5BdycBdxc1UTD6PQ9mtj0wzt3vLGWwEsrna2ETYBMze9TMnuhaTaya5HMOfgwca2YLgLuAr5cmWvnrd8UiKR9mdizQDAy6hSYtuyDrpcAJAUcJWg3Zbpc9yf6m9rCZbe3uHwQZqsSOBv7s7peY2a7AX81sK3fPBB0saEFfoWtq3vzOAWa2N/B94BB3T5YoWyn1dx4aga2Ah8zsv8AuwPQquzGaz9fCAmC6u6fdfS7wGtkCXy3yOQcnATcDuPvjQC3ZSbsGvaALuqbmzeMcmNl2wJVki3m19Zl+aLXnwd2XuXuTu09094lk7yUc4u7VtNJ4Pt8Pt5O9OsfMmsh2wax2ZtMKk885eAvYC8DMNidb0LUEGgEX9K4+8VOBGcDLwM3u/pKZnWdmh3Tt9idghJnNAU4H+hzOVonyPAcXkV05+BYzm2VmPb/AK16e56Gq5XkOZgBLzGw28CBwprtXzW+seZ6DbwNfNrPngBuAE6rsIm/A9Oi/iEiVCLrLRURECkQFXUSkSqigi4hUCRV0EZEqoYIuIlIlVNBFRKqECrqISJX4f2ZggFUi2sfuAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Next, the datasets and dataloader are created from the tensors. The first 4*batch_size samples are being used as the training set and the remaining batch_size samples are the test set. The splitting of datasets is not necessary for now but will make extension easy later on.\n","\n","Tensordata requires a 2D tensor, where each line represents one training sample. Targets may be 1-D or 2-D."],"metadata":{"id":"6Z-BuRePpr2U"}},{"cell_type":"code","source":["train_set = TensorDataset(artifical_data[:n_train_batches*batch_size,], artifical_labels[:n_train_batches*batch_size,])\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n","print(f'Number of datapoints in the training set is {len(train_set)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZF5qogHZpBgA","executionInfo":{"status":"ok","timestamp":1679657339578,"user_tz":-60,"elapsed":84,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"aab92239-62a5-4507-ee89-e552166350ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of datapoints in the training set is 28\n"]}]},{"cell_type":"code","source":["eval_set = TensorDataset(artifical_data[n_train_batches*batch_size:,], artifical_labels[n_train_batches*batch_size:,])\n","eval_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n","print(f'Number of datapoints in the evaluation set is {len(eval_set)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEk_Tcezpt23","executionInfo":{"status":"ok","timestamp":1679657339578,"user_tz":-60,"elapsed":80,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"352831dd-a7df-4039-b36a-db62d79e5148"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of datapoints in the evaluation set is 12\n"]}]},{"cell_type":"code","source":["dataloaders = {'train':train_loader,\n","               'eval':eval_loader}"],"metadata":{"id":"3fE9wU5Mp0gb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Create sample model\n","The base model architecture and weights are taken from [here](https://www.kaggle.com/code/sironghuang/understanding-pytorch-hooks) for reference."],"metadata":{"id":"z2DBn9rVp4sP"}},{"cell_type":"code","source":["class TestModel(nn.Module):\n","  def __init__(self, dropout_rate = 0.5):\n","        super().__init__()\n","        # self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(2,2)\n","        self.s1 = nn.Sigmoid()\n","        self.do1 = nn.Dropout(p=dropout_rate)\n","        self.fc2 = nn.Linear(2,1)\n","        self.s2 = nn.Sigmoid()\n","\n","  def forward(self, x):\n","      # x = self.flatten(x)\n","      x= self.fc1(x)\n","      x = self.s1(x)\n","      x = self.do1(x)\n","      x= self.fc2(x)\n","      x = self.s2(x)\n","      return x"],"metadata":{"id":"_U4Oeefjp2co"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = TestModel()\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NhnZHrVaqlD-","executionInfo":{"status":"ok","timestamp":1679657339580,"user_tz":-60,"elapsed":78,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"c1836eab-51ce-4cb1-bff7-1fdfc07266c1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TestModel(\n","  (fc1): Linear(in_features=2, out_features=2, bias=True)\n","  (s1): Sigmoid()\n","  (do1): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=2, out_features=1, bias=True)\n","  (s2): Sigmoid()\n",")\n"]}]},{"cell_type":"code","source":["for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2upreNpUqlZq","executionInfo":{"status":"ok","timestamp":1679657339581,"user_tz":-60,"elapsed":75,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"70e5e4a6-5e9d-44cb-af7c-35388ffde28c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Layer: fc1.weight | Size: torch.Size([2, 2]) | Values : tensor([[-0.6590,  0.6283],\n","        [ 0.5377, -0.7054]], grad_fn=<SliceBackward0>) \n","\n","Layer: fc1.bias | Size: torch.Size([2]) | Values : tensor([ 0.1324, -0.1191], grad_fn=<SliceBackward0>) \n","\n","Layer: fc2.weight | Size: torch.Size([1, 2]) | Values : tensor([[-0.1164, -0.3237]], grad_fn=<SliceBackward0>) \n","\n","Layer: fc2.bias | Size: torch.Size([1]) | Values : tensor([0.2719], grad_fn=<SliceBackward0>) \n","\n"]}]},{"cell_type":"markdown","source":["# Prepare pretraining optimizer and loss function"],"metadata":{"id":"Bji47h-EqsK_"}},{"cell_type":"code","source":["adam_parameters = {\n","    'lr':1e-3,              # 1e-3\n","    'betas':(0.9,0.999),    # (0.9,0.999)\n","    'eps':1e-08,            # 1e-08\n","    'weight_decay':0.01     # 0.01\n","    # rest also standard\n","}\n","pretrain_optimizer = torch.optim.AdamW(model.parameters(), **adam_parameters)"],"metadata":{"id":"QjOAJ5RRqnDv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["loss_fn = nn.BCELoss()"],"metadata":{"id":"LLhmBK9vrTwG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training Loop"],"metadata":{"id":"YYR2cDe5rhWB"}},{"cell_type":"code","source":["def train_model(model, dataloaders, loss_fn, optimizer, num_epochs=5):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    n_train_batches = len(dataloaders['train'])\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        ########## train phase ##########\n","        phase = 'train'\n","        model.train()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for batch, (inputs, labels) in enumerate(dataloaders[phase]):\n","          model.train()\n","          optimizer.zero_grad()\n","          outputs = model(inputs)\n","          loss = loss_fn(outputs, labels.float())\n","          loss.backward()          \n","          optimizer.step()\n","\n","          running_loss += loss.item() * inputs.size(0)\n","          preds = (outputs>0.5).int()\n","          running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","        ########## eval phase ##########\n","        phase = 'eval'\n","        model.eval()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for batch, (inputs, labels) in enumerate(dataloaders[phase]):\n","          # disable gradient tracking for speedup\n","          with torch.set_grad_enabled(phase == 'train'):\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, labels.float())\n","            preds = (outputs>0.5).int()\n","\n","          running_loss += loss.item() * inputs.size(0)\n","          running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))  \n","\n","        val_acc_history.append(epoch_acc)\n","        print()\n","\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","\n","    return val_acc_history"],"metadata":{"id":"FnH-LPFlrUNS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Pretraining the model"],"metadata":{"id":"2z9L2DdcsY6W"}},{"cell_type":"code","source":["hist = train_model(model,\n","                   dataloaders,\n","                   loss_fn,\n","                   pretrain_optimizer,\n","                   num_epochs=3\n","                   )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1CQpp1s3sbSG","executionInfo":{"status":"ok","timestamp":1679657339583,"user_tz":-60,"elapsed":66,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"ea849525-09d6-431b-bd5c-cfe9aab4ddf7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/2\n","----------\n","train Loss: 0.7156 Acc: 0.3571\n","eval Loss: 0.6928 Acc: 0.5357\n","\n","Epoch 1/2\n","----------\n","train Loss: 0.6911 Acc: 0.4643\n","eval Loss: 0.6928 Acc: 0.5357\n","\n","Epoch 2/2\n","----------\n","train Loss: 0.6922 Acc: 0.4286\n","eval Loss: 0.6927 Acc: 0.5357\n","\n","Training complete in 0m 0s\n"]}]},{"cell_type":"markdown","source":["# Getting infos about the state of the pretrained model + optimizer"],"metadata":{"id":"P7QnUvnCsza-"}},{"cell_type":"code","source":["pretrain_state = pretrain_optimizer.state\n","pretrain_state_dict = pretrain_optimizer.state_dict()"],"metadata":{"id":"i7Jx1qiY0DOM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IQT6ELoHzdAQ","executionInfo":{"status":"ok","timestamp":1679657339584,"user_tz":-60,"elapsed":57,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"c6650e51-4c6c-420b-c7e9-cb8967c51a5d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["OrderedDict([('fc1.weight', tensor([[-0.6540,  0.6302],\n","                      [ 0.5404, -0.7041]])),\n","             ('fc1.bias', tensor([ 0.1213, -0.1268])),\n","             ('fc2.weight', tensor([[-0.1059, -0.3160]])),\n","             ('fc2.bias', tensor([0.2736]))])"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["pretrain_state_dict['state']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11oqcJtF3Sqe","executionInfo":{"status":"ok","timestamp":1679657339585,"user_tz":-60,"elapsed":48,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"8a327c8e-b392-4a36-9db4-8463de1e4faf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: {'step': tensor(21.), 'exp_avg': tensor([[-0.0012, -0.0012],\n","          [-0.0071, -0.0068]]), 'exp_avg_sq': tensor([[4.1392e-07, 4.8464e-07],\n","          [5.3632e-06, 5.2507e-06]])},\n"," 1: {'step': tensor(21.),\n","  'exp_avg': tensor([0.0022, 0.0010]),\n","  'exp_avg_sq': tensor([1.4041e-06, 1.5512e-05])},\n"," 2: {'step': tensor(21.),\n","  'exp_avg': tensor([[-0.0408, -0.0066]]),\n","  'exp_avg_sq': tensor([[0.0006, 0.0005]])},\n"," 3: {'step': tensor(21.),\n","  'exp_avg': tensor([-0.0100]),\n","  'exp_avg_sq': tensor([0.0013])}}"]},"metadata":{},"execution_count":85}]},{"cell_type":"markdown","source":["# Changes to make\n","- hand the weights and exp_avg_sq from the pretrained model to the adamw optimizer\n","- We need to correct the exp_avg_sq from the pretrained model to the normalized one."],"metadata":{"id":"WsEbT9_4Cr-k"}},{"cell_type":"code","source":["adam_parameters = {\n","    'lr':1e-3,              # 1e-3\n","    'betas':(0.9,0.999),    # (0.9,0.999)\n","    'eps':1e-08,            # 1e-08\n","    'weight_decay':0.01     # 0.01\n","    # rest also standard\n","}\n","finetune_optimizer = AdamW_modified(model.parameters(), **adam_parameters)"],"metadata":{"id":"s3NEqluD5bJG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pretrain_optimizer.state[pretrain_optimizer.param_groups[0]['params'][0]]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q62iaD4QOLOl","executionInfo":{"status":"ok","timestamp":1679657686513,"user_tz":-60,"elapsed":7,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"1ea5ca0f-0c8d-4a15-8d0c-c39dc9740252"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'step': tensor(21.), 'exp_avg': tensor([[-0.0012, -0.0012],\n","         [-0.0071, -0.0068]]), 'exp_avg_sq': tensor([[4.1392e-07, 4.8464e-07],\n","         [5.3632e-06, 5.2507e-06]])}"]},"metadata":{},"execution_count":99}]},{"cell_type":"code","source":["pretrain_optimizer.state"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LoC9NNjwVer7","executionInfo":{"status":"ok","timestamp":1679657591011,"user_tz":-60,"elapsed":9,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"61067732-922e-4f28-bdc7-964132f09381"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["defaultdict(dict, {Parameter containing:\n","             tensor([[-0.6445,  0.6382],\n","                     [ 0.5439, -0.7025]], requires_grad=True): {'step': tensor(21.),\n","              'exp_avg': tensor([[-0.0012, -0.0012],\n","                      [-0.0071, -0.0068]]),\n","              'exp_avg_sq': tensor([[4.1392e-07, 4.8464e-07],\n","                      [5.3632e-06, 5.2507e-06]])},\n","             Parameter containing:\n","             tensor([ 0.1194, -0.1354], requires_grad=True): {'step': tensor(21.),\n","              'exp_avg': tensor([0.0022, 0.0010]),\n","              'exp_avg_sq': tensor([1.4041e-06, 1.5512e-05])},\n","             Parameter containing:\n","             tensor([[-0.1042, -0.3075]], requires_grad=True): {'step': tensor(21.),\n","              'exp_avg': tensor([[-0.0408, -0.0066]]),\n","              'exp_avg_sq': tensor([[0.0006, 0.0005]])},\n","             Parameter containing:\n","             tensor([0.2752], requires_grad=True): {'step': tensor(21.),\n","              'exp_avg': tensor([-0.0100]),\n","              'exp_avg_sq': tensor([0.0013])}})"]},"metadata":{},"execution_count":98}]},{"cell_type":"code","source":["pretrain_optimizer.state_dict()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HIQbtw0mZmEj","executionInfo":{"status":"ok","timestamp":1679657700968,"user_tz":-60,"elapsed":1142,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"339fa661-3388-42e7-ff93-7adc6f19604b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'state': {0: {'step': tensor(21.), 'exp_avg': tensor([[-0.0012, -0.0012],\n","           [-0.0071, -0.0068]]), 'exp_avg_sq': tensor([[4.1392e-07, 4.8464e-07],\n","           [5.3632e-06, 5.2507e-06]])},\n","  1: {'step': tensor(21.),\n","   'exp_avg': tensor([0.0022, 0.0010]),\n","   'exp_avg_sq': tensor([1.4041e-06, 1.5512e-05])},\n","  2: {'step': tensor(21.),\n","   'exp_avg': tensor([[-0.0408, -0.0066]]),\n","   'exp_avg_sq': tensor([[0.0006, 0.0005]])},\n","  3: {'step': tensor(21.),\n","   'exp_avg': tensor([-0.0100]),\n","   'exp_avg_sq': tensor([0.0013])}},\n"," 'param_groups': [{'lr': 0.001,\n","   'betas': (0.9, 0.999),\n","   'eps': 1e-08,\n","   'weight_decay': 0.01,\n","   'amsgrad': False,\n","   'foreach': None,\n","   'maximize': False,\n","   'capturable': False,\n","   'differentiable': False,\n","   'fused': None,\n","   'params': [0, 1, 2, 3]}]}"]},"metadata":{},"execution_count":100}]},{"cell_type":"code","source":["hist = train_model(model,\n","                   dataloaders,\n","                   loss_fn,\n","                   finetune_optimizer,\n","                   num_epochs=3\n","                   )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p6Q84ewq7fpo","executionInfo":{"status":"ok","timestamp":1679657339589,"user_tz":-60,"elapsed":36,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"}},"outputId":"a774ef24-6fbb-4873-82ea-22ac518261ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/2\n","----------\n","train Loss: 0.7030 Acc: 0.5000\n","eval Loss: 0.6926 Acc: 0.5357\n","\n","Epoch 1/2\n","----------\n","train Loss: 0.6858 Acc: 0.5714\n","eval Loss: 0.6925 Acc: 0.5357\n","\n","Epoch 2/2\n","----------\n","train Loss: 0.7219 Acc: 0.3929\n","eval Loss: 0.6924 Acc: 0.5357\n","\n","Training complete in 0m 0s\n"]}]},{"cell_type":"code","source":["import torch\n","from torch import Tensor\n","from torch.optim.optimizer import (Optimizer, _use_grad_for_differentiable, _get_value, _dispatch_sqrt,\n","                        _stack_if_compiling, _capturable_doc, _differentiable_doc, _foreach_doc,\n","                        _fused_doc, _maximize_doc, _default_to_fused_or_foreach)\n","from typing import List, Optional\n","from torch.utils._foreach_utils import _group_tensors_by_device_and_dtype\n","\n","__all__ = [\"AdamW\", \"adamw\"]\n","\n","\n","class AdamW_modified(Optimizer):\n","    def __init__(\n","        self,\n","        params,\n","        lr=1e-3,\n","        betas=(0.9, 0.999),\n","        eps=1e-8,\n","        weight_decay=1e-2,\n","        amsgrad=False,\n","        reference_state=None,\n","        *,\n","        maximize: bool = False,\n","        foreach: Optional[bool] = None,\n","        capturable: bool = False,\n","        differentiable: bool = False,\n","        fused: Optional[bool] = None,\n","    ):\n","        self.reference_state= reference_state\n","        if not 0.0 <= lr:\n","            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n","        if not 0.0 <= eps:\n","            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n","        if not 0.0 <= betas[0] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n","        if not 0.0 <= betas[1] < 1.0:\n","            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n","        if not 0.0 <= weight_decay:\n","            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n","        defaults = dict(\n","            lr=lr,\n","            betas=betas,\n","            eps=eps,\n","            weight_decay=weight_decay,\n","            amsgrad=amsgrad,\n","            foreach=foreach,\n","            maximize=maximize,\n","            capturable=capturable,\n","            differentiable=differentiable,\n","            fused=fused,\n","        )\n","        super().__init__(params, defaults)\n","\n","        if fused:\n","            if differentiable:\n","                raise RuntimeError(\"`fused` does not support `differentiable`\")\n","            self._step_supports_amp_scaling = True\n","            # TODO(crcrpar): [low prec params & their higher prec copy]\n","            # Suppor AMP with FP16/BF16 model params which would need\n","            # higher prec copy of params to do update math in higher prec to\n","            # alleviate the loss of information.\n","            if not all(\n","                p.is_cuda and torch.is_floating_point(p)\n","                for pg in self.param_groups for p in pg['params']\n","            ):\n","                raise RuntimeError(\"`fused=True` requires all the params to be CUDA, floating point Tensor\")\n","            if foreach:\n","                raise RuntimeError(\"`fused` and `foreach` cannot be `True` together.\")\n","        \n","    def __setstate__(self, state):\n","        super().__setstate__(state)\n","        for group in self.param_groups:\n","            group.setdefault(\"amsgrad\", False)\n","            group.setdefault(\"maximize\", False)\n","            group.setdefault(\"foreach\", None)\n","            group.setdefault(\"capturable\", False)\n","            group.setdefault(\"differentiable\", False)\n","            group.setdefault(\"fused\", None)\n","        state_values = list(self.state.values())\n","        step_is_tensor = (len(state_values) != 0) and torch.is_tensor(\n","            state_values[0][\"step\"]\n","        )\n","        if not step_is_tensor:\n","            for s in state_values:\n","                s[\"step\"] = torch.tensor(float(s[\"step\"]))\n","\n","    def _init_group(\n","        self,\n","        group,\n","        params_with_grad,\n","        grads,\n","        amsgrad,\n","        exp_avgs,\n","        exp_avg_sqs,\n","        max_exp_avg_sqs,\n","        state_steps,\n","        ref_parameters,\n","        ref_norm_avg_sqs\n","    ):\n","        for p in group[\"params\"]:\n","            if p.grad is None:\n","                continue\n","            params_with_grad.append(p)\n","            if p.grad.is_sparse:\n","                raise RuntimeError(\"AdamW does not support sparse gradients\")\n","            grads.append(p.grad)\n","\n","            state = self.state[p]\n","\n","            # State initialization\n","            if len(state) == 0:\n","                # note(crcrpar): Deliberately host `step` on CPU if both capturable and fused are off.\n","                # This is because kernel launches are costly on CUDA and XLA.\n","                state[\"step\"] = (\n","                    torch.zeros((), dtype=torch.float, device=p.device)\n","                    if group[\"capturable\"] or group[\"fused\"]\n","                    else torch.tensor(0.0)\n","                )\n","                # Exponential moving average of gradient values\n","                state[\"exp_avg\"] = torch.zeros_like(\n","                    p, memory_format=torch.preserve_format\n","                )\n","                # Exponential moving average of squared gradient values\n","                state[\"exp_avg_sq\"] = torch.zeros_like(\n","                    p, memory_format=torch.preserve_format\n","                )\n","                if amsgrad:\n","                    # Maintains max of all exp. moving avg. of sq. grad. values\n","                    state[\"max_exp_avg_sq\"] = torch.zeros_like(\n","                        p, memory_format=torch.preserve_format\n","                    )\n","                # # attach reference parameters\n","                if self.reference_state is not None:\n","                  # ref_avg_sq should be normalized, especially for pretrained models\n","                  # with small number of steps. For now assume steps >> 0 and therefore\n","                  # (1-beta2^step) = 1\n","                  state[\"ref_norm_exp_avg_sq\"] = self.reference_state[p][\"exp_avg_sq\"]\n","                  # \n","                  state[\"ref_parameters\"] = p\n","                  \n","\n","            exp_avgs.append(state[\"exp_avg\"])\n","            exp_avg_sqs.append(state[\"exp_avg_sq\"])\n","\n","            if amsgrad:\n","                max_exp_avg_sqs.append(state[\"max_exp_avg_sq\"])\n","\n","            ref_parameters.append(state[\"ref_parameters\"])\n","            ref_norm_avg_sqs.append(state[\"ref_norm_exp_avg_sq\"])\n","\n","            state_steps.append(state[\"step\"])\n","\n","    @_use_grad_for_differentiable\n","    def step(self, closure=None):\n","        \"\"\"Performs a single optimization step.\n","        Args:\n","            closure (Callable, optional): A closure that reevaluates the model\n","                and returns the loss.\n","        \"\"\"\n","        self._cuda_graph_capture_health_check()\n","\n","        loss = None\n","        if closure is not None:\n","            with torch.enable_grad():\n","                loss = closure()\n","\n","        for group in self.param_groups:\n","            params_with_grad = []\n","            grads = []\n","            exp_avgs = []\n","            exp_avg_sqs = []\n","            max_exp_avg_sqs = []\n","            state_steps = []\n","            amsgrad = group[\"amsgrad\"]\n","            beta1, beta2 = group[\"betas\"]\n","            ref_parameters = []\n","            ref_norm_avg_sqs = []\n","\n","            self._init_group(\n","                group,\n","                params_with_grad,\n","                grads,\n","                amsgrad,\n","                exp_avgs,\n","                exp_avg_sqs,\n","                max_exp_avg_sqs,\n","                state_steps,\n","                ref_parameters,\n","                ref_norm_avg_sqs\n","            )\n","\n","            adamw_modified(\n","                params_with_grad,\n","                grads,\n","                exp_avgs,\n","                exp_avg_sqs,\n","                max_exp_avg_sqs,\n","                state_steps,\n","                amsgrad=amsgrad,\n","                beta1=beta1,\n","                beta2=beta2,\n","                lr=group[\"lr\"],\n","                weight_decay=group[\"weight_decay\"],\n","                eps=group[\"eps\"],\n","                maximize=group[\"maximize\"],\n","                foreach=group[\"foreach\"],\n","                capturable=group[\"capturable\"],\n","                differentiable=group[\"differentiable\"],\n","                fused=group[\"fused\"],\n","                grad_scale=getattr(self, \"grad_scale\", None),\n","                found_inf=getattr(self, \"found_inf\", None),\n","                ref_parameters=ref_parameters,\n","                ref_norm_avg_sqs=ref_norm_avg_sqs\n","            )\n","\n","        return loss\n","\n","\n","AdamW_modified.__doc__ = r\"\"\"Implements AdamW algorithm.\n","    .. math::\n","       \\begin{aligned}\n","            &\\rule{110mm}{0.4pt}                                                                 \\\\\n","            &\\textbf{input}      : \\gamma \\text{(lr)}, \\: \\beta_1, \\beta_2\n","                \\text{(betas)}, \\: \\theta_0 \\text{(params)}, \\: f(\\theta) \\text{(objective)},\n","                \\: \\epsilon \\text{ (epsilon)}                                                    \\\\\n","            &\\hspace{13mm}      \\lambda \\text{(weight decay)},  \\: \\textit{amsgrad},\n","                \\: \\textit{maximize}                                                             \\\\\n","            &\\textbf{initialize} : m_0 \\leftarrow 0 \\text{ (first moment)}, v_0 \\leftarrow 0\n","                \\text{ ( second moment)}, \\: \\widehat{v_0}^{max}\\leftarrow 0              \\\\[-1.ex]\n","            &\\rule{110mm}{0.4pt}                                                                 \\\\\n","            &\\textbf{for} \\: t=1 \\: \\textbf{to} \\: \\ldots \\: \\textbf{do}                         \\\\\n","            &\\hspace{5mm}\\textbf{if} \\: \\textit{maximize}:                                       \\\\\n","            &\\hspace{10mm}g_t           \\leftarrow   -\\nabla_{\\theta} f_t (\\theta_{t-1})          \\\\\n","            &\\hspace{5mm}\\textbf{else}                                                           \\\\\n","            &\\hspace{10mm}g_t           \\leftarrow   \\nabla_{\\theta} f_t (\\theta_{t-1})           \\\\\n","            &\\hspace{5mm} \\theta_t \\leftarrow \\theta_{t-1} - \\gamma \\lambda \\theta_{t-1}         \\\\\n","            &\\hspace{5mm}m_t           \\leftarrow   \\beta_1 m_{t-1} + (1 - \\beta_1) g_t          \\\\\n","            &\\hspace{5mm}v_t           \\leftarrow   \\beta_2 v_{t-1} + (1-\\beta_2) g^2_t          \\\\\n","            &\\hspace{5mm}\\widehat{m_t} \\leftarrow   m_t/\\big(1-\\beta_1^t \\big)                   \\\\\n","            &\\hspace{5mm}\\widehat{v_t} \\leftarrow   v_t/\\big(1-\\beta_2^t \\big)                   \\\\\n","            &\\hspace{5mm}\\textbf{if} \\: amsgrad                                                  \\\\\n","            &\\hspace{10mm}\\widehat{v_t}^{max} \\leftarrow \\mathrm{max}(\\widehat{v_t}^{max},\n","                \\widehat{v_t})                                                                   \\\\\n","            &\\hspace{10mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t}/\n","                \\big(\\sqrt{\\widehat{v_t}^{max}} + \\epsilon \\big)                                 \\\\\n","            &\\hspace{5mm}\\textbf{else}                                                           \\\\\n","            &\\hspace{10mm}\\theta_t \\leftarrow \\theta_t - \\gamma \\widehat{m_t}/\n","                \\big(\\sqrt{\\widehat{v_t}} + \\epsilon \\big)                                       \\\\\n","            &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n","            &\\bf{return} \\:  \\theta_t                                                     \\\\[-1.ex]\n","            &\\rule{110mm}{0.4pt}                                                          \\\\[-1.ex]\n","       \\end{aligned}\n","    For further details regarding the algorithm we refer to `Decoupled Weight Decay Regularization`_.\n","    \"\"\" + r\"\"\"\n","    Args:\n","        params (iterable): iterable of parameters to optimize or dicts defining\n","            parameter groups\n","        lr (float, optional): learning rate (default: 1e-3)\n","        betas (Tuple[float, float], optional): coefficients used for computing\n","            running averages of gradient and its square (default: (0.9, 0.999))\n","        eps (float, optional): term added to the denominator to improve\n","            numerical stability (default: 1e-8)\n","        weight_decay (float, optional): weight decay coefficient (default: 1e-2)\n","        amsgrad (bool, optional): whether to use the AMSGrad variant of this\n","            algorithm from the paper `On the Convergence of Adam and Beyond`_\n","            (default: False)\n","        {maximize}\n","        {foreach}\n","        {capturable}\n","        {differentiable}\n","        {fused}\n","    .. _Decoupled Weight Decay Regularization:\n","        https://arxiv.org/abs/1711.05101\n","    .. _On the Convergence of Adam and Beyond:\n","        https://openreview.net/forum?id=ryQu7f-RZ\n","    \"\"\".format(maximize=_maximize_doc,\n","               foreach=_foreach_doc,\n","               fused=_fused_doc,\n","               capturable=_capturable_doc,\n","               differentiable=_differentiable_doc)\n","\n","\n","def adamw_modified(\n","    params: List[Tensor],\n","    grads: List[Tensor],\n","    exp_avgs: List[Tensor],\n","    exp_avg_sqs: List[Tensor],\n","    max_exp_avg_sqs: List[Tensor],\n","    state_steps: List[Tensor],\n","    # kwonly args with defaults are not supported by functions compiled with torchscript issue #70627\n","    # setting this as kwarg for now as functional API is compiled by torch/distributed/optim\n","    foreach: Optional[bool] = None,\n","    capturable: bool = False,\n","    differentiable: bool = False,\n","    fused: Optional[bool] = None,\n","    grad_scale: Optional[Tensor] = None,\n","    found_inf: Optional[Tensor] = None,\n","    *,\n","    amsgrad: bool,\n","    beta1: float,\n","    beta2: float,\n","    lr: float,\n","    weight_decay: float,\n","    eps: float,\n","    maximize: bool,\n","    ref_parameters : List[Tensor],\n","    ref_norm_avg_sqs : List[Tensor]\n","):\n","    r\"\"\"Functional API that performs AdamW algorithm computation.\n","    See :class:`~torch.optim.AdamW` for details.\n","    \"\"\"\n","\n","    if not all(isinstance(t, torch.Tensor) for t in state_steps):\n","        raise RuntimeError(\n","            \"API has changed, `state_steps` argument must contain a list of singleton tensors\"\n","        )\n","\n","    # Respect when the user inputs False/True for foreach or fused. We only want to change\n","    # the default when neither have been user-specified. Note that we default to foreach\n","    # and pass False to use_fused. This is not a mistake--we want to give the fused impl\n","    # bake-in time before making it the default, even if it is typically faster.\n","    if fused is None and foreach is None:\n","        _, foreach = _default_to_fused_or_foreach(params, differentiable, use_fused=False)\n","    if fused is None:\n","        fused = False\n","    if foreach is None:\n","        foreach = False\n","\n","    if foreach and torch.jit.is_scripting():\n","        raise RuntimeError(\"torch.jit.script not supported with foreach optimizers\")\n","    if fused and torch.jit.is_scripting():\n","        raise RuntimeError(\"torch.jit.script not supported with fused optimizers\")\n","\n","    if fused and not torch.jit.is_scripting():\n","        func = _fused_adamw\n","    elif foreach and not torch.jit.is_scripting():\n","        func = _multi_tensor_adamw\n","    else:\n","        func = _single_tensor_adamw\n","\n","    func(\n","        params,\n","        grads,\n","        exp_avgs,\n","        exp_avg_sqs,\n","        max_exp_avg_sqs,\n","        state_steps,\n","        amsgrad=amsgrad,\n","        beta1=beta1,\n","        beta2=beta2,\n","        lr=lr,\n","        weight_decay=weight_decay,\n","        eps=eps,\n","        maximize=maximize,\n","        capturable=capturable,\n","        differentiable=differentiable,\n","        grad_scale=grad_scale,\n","        found_inf=found_inf,\n","        ref_parameters=ref_parameters,\n","        ref_norm_avg_sqs=ref_norm_avg_sqs\n","    )\n","\n","\n","def _single_tensor_adamw(\n","    params: List[Tensor],\n","    grads: List[Tensor],\n","    exp_avgs: List[Tensor],\n","    exp_avg_sqs: List[Tensor],\n","    max_exp_avg_sqs: List[Tensor],\n","    state_steps: List[Tensor],\n","    grad_scale: Optional[Tensor],\n","    found_inf: Optional[Tensor],\n","    *,\n","    amsgrad: bool,\n","    beta1: float,\n","    beta2: float,\n","    lr: float,\n","    weight_decay: float,\n","    eps: float,\n","    maximize: bool,\n","    capturable: bool,\n","    differentiable: bool,\n","    ref_parameters : List[Tensor],\n","    ref_norm_avg_sqs : List[Tensor]\n","):\n","\n","    assert grad_scale is None and found_inf is None\n","    for i, param in enumerate(params):\n","        grad = grads[i] if not maximize else -grads[i]\n","        exp_avg = exp_avgs[i]\n","        exp_avg_sq = exp_avg_sqs[i]\n","        step_t = state_steps[i]\n","\n","        if capturable:\n","            assert (\n","                param.is_cuda and step_t.is_cuda\n","            ), \"If capturable=True, params and state_steps must be CUDA tensors.\" \n","\n","        if torch.is_complex(param):\n","            grad = torch.view_as_real(grad)\n","            exp_avg = torch.view_as_real(exp_avg)\n","            exp_avg_sq = torch.view_as_real(exp_avg_sq)\n","            param = torch.view_as_real(param)\n","\n","        # update step\n","        step_t += 1\n","        \n","        \n","        #print(param)\n","        ###########################################################################################\n","        # Perform stepweight decay \n","        ref_parameter = ref_parameters[i]\n","        ref_norm_avg_sq = ref_norm_avg_sqs[i]\n","        param.mul_(1 - (lr * weight_decay)/(ref_norm_avg_sq+eps))\n","\n","        # param.mul_(1 - lr * weight_decay)\n","        \n","        ###########################################################################################\n","        # add pretrained weights\n","       \n","        # Decay the first and second moment running average coefficient\n","        exp_avg.mul_(beta1).add_(grad, alpha=1 - beta1)\n","        exp_avg_sq.mul_(beta2).addcmul_(grad, grad, value=1 - beta2)\n","\n","        if capturable or differentiable:\n","            step = step_t\n","\n","            # 1 - beta1 ** step can't be captured in a CUDA graph, even if step is a CUDA tensor\n","            # (incurs \"RuntimeError: CUDA error: operation not permitted when stream is capturing\")\n","            bias_correction1 = 1 - torch.pow(beta1, step)\n","            bias_correction2 = 1 - torch.pow(beta2, step)\n","\n","            step_size = lr / bias_correction1\n","            step_size_neg = step_size.neg()\n","\n","            bias_correction2_sqrt = bias_correction2.sqrt()\n","\n","            if amsgrad:\n","                # Maintains the maximum of all 2nd moment running avg. till now\n","                if differentiable:\n","                    max_exp_avg_sqs_i = max_exp_avg_sqs[i].clone()\n","                else:\n","                    max_exp_avg_sqs_i = max_exp_avg_sqs[i]\n","                max_exp_avg_sqs[i].copy_(torch.maximum(max_exp_avg_sqs_i, exp_avg_sq))\n","                # Uses the max. for normalizing running avg. of gradient\n","                # Folds in (admittedly ugly) 1-elem step_size math here to avoid extra param-set-sized read+write\n","                # (can't fold it into addcdiv_ below because addcdiv_ requires value is a Number, not a Tensor)\n","                denom = (\n","                    max_exp_avg_sqs[i].sqrt() / (bias_correction2_sqrt * step_size_neg)\n","                ).add_(eps / step_size_neg)\n","            else:\n","                denom = (\n","                    exp_avg_sq.sqrt() / (bias_correction2_sqrt * step_size_neg)\n","                ).add_(eps / step_size_neg)\n","            #####################################\n","            \n","            \n","            param.addcdiv_(exp_avg, denom)\n","        else:\n","            step = _get_value(step_t)\n","\n","            bias_correction1 = 1 - beta1 ** step\n","            bias_correction2 = 1 - beta2 ** step\n","\n","            step_size = lr / bias_correction1\n","\n","            bias_correction2_sqrt = _dispatch_sqrt(bias_correction2)\n","\n","            if amsgrad:\n","                # Maintains the maximum of all 2nd moment running avg. till now\n","                torch.maximum(max_exp_avg_sqs[i], exp_avg_sq, out=max_exp_avg_sqs[i])\n","                # Use the max. for normalizing running avg. of gradient\n","                denom = (max_exp_avg_sqs[i].sqrt() / bias_correction2_sqrt).add_(eps)\n","            else:\n","                denom = (exp_avg_sq.sqrt() / bias_correction2_sqrt).add_(eps)\n","            \n","            \n","            #######################################\n","            param.addcdic_(weights_decay)\n","            param.addcdiv_(exp_avg, denom, value=-step_size)\n","\n","\n","def _multi_tensor_adamw(\n","    params: List[Tensor],\n","    grads: List[Tensor],\n","    exp_avgs: List[Tensor],\n","    exp_avg_sqs: List[Tensor],\n","    max_exp_avg_sqs: List[Tensor],\n","    state_steps: List[Tensor],\n","    grad_scale: Optional[Tensor],\n","    found_inf: Optional[Tensor],\n","    *,\n","    amsgrad: bool,\n","    beta1: float,\n","    beta2: float,\n","    lr: float,\n","    weight_decay: float,\n","    eps: float,\n","    maximize: bool,\n","    capturable: bool,\n","    differentiable: bool,\n","):\n","    if len(params) == 0:\n","        return\n","\n","    if capturable:\n","        assert all(\n","            p.is_cuda and step.is_cuda for p, step in zip(params, state_steps)\n","        ), \"If capturable=True, params and state_steps must be CUDA tensors.\"\n","\n","    assert not differentiable, \"_foreach ops don't support autograd\"\n","\n","    assert grad_scale is None and found_inf is None\n","\n","    grouped_tensors = _group_tensors_by_device_and_dtype([\n","        params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps])\n","    for (device_params, device_grads, device_exp_avgs, device_exp_avg_sqs,\n","         device_max_exp_avg_sqs, device_state_steps) in grouped_tensors.values():\n","        if maximize:\n","            device_grads = torch._foreach_neg(tuple(device_grads))  # type: ignore[assignment]\n","\n","\n","        device_grads = [torch.view_as_real(x) if torch.is_complex(x) else x for x in device_grads]\n","        device_exp_avgs = [torch.view_as_real(x) if torch.is_complex(x) else x for x in device_exp_avgs]\n","        device_exp_avg_sqs = [\n","            torch.view_as_real(x) if torch.is_complex(x) else x for x in device_exp_avg_sqs\n","        ]\n","        device_params = [torch.view_as_real(x) if torch.is_complex(x) else x for x in device_params]\n","\n","        # update steps\n","        torch._foreach_add_(device_state_steps, 1)\n","\n","        # Perform stepweight decay\n","        torch._foreach_mul_(device_params, 1 - lr * weight_decay)\n","        print(device_params)\n","            \n","        # Decay the first and second moment running average coefficient\n","        torch._foreach_mul_(device_exp_avgs, beta1)\n","        torch._foreach_add_(device_exp_avgs, device_grads, alpha=1 - beta1)\n","\n","        torch._foreach_mul_(device_exp_avg_sqs, beta2)\n","        torch._foreach_addcmul_(device_exp_avg_sqs, device_grads, device_grads, 1 - beta2)\n","\n","        if capturable:\n","            bias_correction1 = torch._foreach_pow(beta1, device_state_steps)\n","            bias_correction2 = torch._foreach_pow(beta2, device_state_steps)\n","            # foreach_sub doesn't allow a scalar as the first arg\n","            torch._foreach_sub_(bias_correction1, 1)\n","            torch._foreach_sub_(bias_correction2, 1)\n","            torch._foreach_neg_(bias_correction1)\n","            torch._foreach_neg_(bias_correction2)\n","\n","            # foreach_div doesn't allow a scalar as the first arg\n","            step_size = torch._foreach_div(bias_correction1, lr)\n","            torch._foreach_reciprocal_(step_size)\n","            torch._foreach_neg_(step_size)\n","\n","            bias_correction2_sqrt = torch._foreach_sqrt(bias_correction2)\n","\n","            if amsgrad:\n","                # Maintains the maximum of all 2nd moment running avg. till now\n","                torch._foreach_maximum_(device_max_exp_avg_sqs, device_exp_avg_sqs)\n","\n","                # Use the max. for normalizing running avg. of gradient\n","                max_exp_avg_sq_sqrt = torch._foreach_sqrt(device_max_exp_avg_sqs)\n","                # Folds in (admittedly ugly) 1-elem step_size math here to avoid extra param-set-sized read+write\n","                # (can't fold it into addcdiv_ below because addcdiv_ requires value is a Number, not a Tensor)\n","                torch._foreach_div_(\n","                    max_exp_avg_sq_sqrt,\n","                    torch._foreach_mul(bias_correction2_sqrt, step_size),\n","                )\n","                eps_over_step_size = torch._foreach_div(step_size, eps)\n","                torch._foreach_reciprocal_(eps_over_step_size)\n","                denom = torch._foreach_add(max_exp_avg_sq_sqrt, eps_over_step_size)\n","            else:\n","                exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n","                torch._foreach_div_(\n","                    exp_avg_sq_sqrt, torch._foreach_mul(bias_correction2_sqrt, step_size)\n","                )\n","                eps_over_step_size = torch._foreach_div(step_size, eps)\n","                torch._foreach_reciprocal_(eps_over_step_size)\n","                denom = torch._foreach_add(exp_avg_sq_sqrt, eps_over_step_size)\n","\n","            torch._foreach_addcdiv_(device_params, device_exp_avgs, denom)\n","        else:\n","            bias_correction1 = [1 - beta1 ** _get_value(step) for step in device_state_steps]\n","            bias_correction2 = [1 - beta2 ** _get_value(step) for step in device_state_steps]\n","\n","            step_size = _stack_if_compiling([(lr / bc) * -1 for bc in bias_correction1])\n","\n","            bias_correction2_sqrt = [_dispatch_sqrt(bc) for bc in bias_correction2]\n","\n","            if amsgrad:\n","                # Maintains the maximum of all 2nd moment running avg. till now\n","                torch._foreach_maximum_(device_max_exp_avg_sqs, device_exp_avg_sqs)\n","\n","                # Use the max. for normalizing running avg. of gradient\n","                max_exp_avg_sq_sqrt = torch._foreach_sqrt(device_max_exp_avg_sqs)\n","                torch._foreach_div_(max_exp_avg_sq_sqrt, bias_correction2_sqrt)\n","                denom = torch._foreach_add(max_exp_avg_sq_sqrt, eps)\n","            else:\n","                exp_avg_sq_sqrt = torch._foreach_sqrt(device_exp_avg_sqs)\n","                torch._foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n","                denom = torch._foreach_add(exp_avg_sq_sqrt, eps)\n","\n","            torch._foreach_addcdiv_(device_params, device_exp_avgs, denom, step_size)\n","\n","\n","def _fused_adamw(\n","    params: List[Tensor],\n","    grads: List[Tensor],\n","    exp_avgs: List[Tensor],\n","    exp_avg_sqs: List[Tensor],\n","    max_exp_avg_sqs: List[Tensor],\n","    state_steps: List[Tensor],\n","    grad_scale: Optional[Tensor],\n","    found_inf: Optional[Tensor],\n","    *,\n","    amsgrad: bool,\n","    beta1: float,\n","    beta2: float,\n","    lr: float,\n","    weight_decay: float,\n","    eps: float,\n","    maximize: bool,\n","    capturable: bool,  # Needed for consistency.\n","    differentiable: bool,\n",") -> None:\n","    if differentiable:\n","        raise RuntimeError(\"_fused_adamw is not differentiable\")\n","    grad_scale_dict = {grad_scale.device: grad_scale} if grad_scale is not None else None\n","    found_inf_dict = {found_inf.device: found_inf} if found_inf is not None else None\n","    grouped_tensors = _group_tensors_by_device_and_dtype([params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps])\n","    for (device, dtype) in grouped_tensors:\n","        (\n","            device_params,\n","            device_grads,\n","            device_exp_avgs,\n","            device_exp_avg_sqs,\n","            device_max_exp_avg_sqs,\n","            device_state_steps,\n","        ) = grouped_tensors[(device, dtype)]\n","        device_grad_scale, device_found_inf = None, None\n","        if grad_scale is not None:\n","            if device not in grad_scale_dict:\n","                grad_scale_dict[device] = grad_scale.to(device, non_blocking=True)\n","            device_grad_scale = grad_scale_dict[device]\n","        if found_inf is not None:\n","            if found_inf not in found_inf_dict:\n","                found_inf_dict[device] = found_inf.to(device, non_blocking=True)\n","            device_found_inf = found_inf_dict[device]\n","        torch._foreach_add_(device_state_steps, 1)\n","        torch._fused_adamw_(\n","            device_params,\n","            device_grads,\n","            device_exp_avgs,\n","            device_exp_avg_sqs,\n","            device_max_exp_avg_sqs,\n","            device_state_steps,\n","            amsgrad=amsgrad,\n","            lr=lr,\n","            beta1=beta1,\n","            beta2=beta2,\n","            weight_decay=weight_decay,\n","            eps=eps,\n","            maximize=maximize,\n","            grad_scale=device_grad_scale,\n","            found_inf=device_found_inf,\n","        )\n","        if device_found_inf is not None:\n","            torch._foreach_sub_(device_state_steps, [device_found_inf] * len(device_state_steps))\n"],"metadata":{"id":"giexUcRu7o-L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"aq2ghAKfSEwY"},"execution_count":null,"outputs":[]}]}