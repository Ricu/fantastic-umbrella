{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":111836,"status":"ok","timestamp":1679397934842,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"u_8PYUQi5FQS"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (1.13.1+cu116)\n","Collecting torch\n","  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (0.14.1+cu116)\n","Collecting torchvision\n","  Downloading torchvision-0.15.1-cp39-cp39-manylinux1_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting triton==2.0.0\n","  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch) (3.1.2)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch) (3.0)\n","Collecting nvidia-cusparse-cu11==11.7.4.91\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch) (4.5.0)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch) (3.10.0)\n","Collecting nvidia-cublas-cu11==11.10.3.66\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch) (1.11.1)\n","Collecting nvidia-nvtx-cu11==11.7.91\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66-\u003etorch) (63.4.3)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (from nvidia-cublas-cu11==11.10.3.66-\u003etorch) (0.40.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0-\u003etorch) (3.25.2)\n","Collecting lit\n","  Downloading lit-16.0.0.tar.gz (144 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 KB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision) (2.27.1)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision) (8.4.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2-\u003etorch) (2.1.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision) (3.4)\n","Requirement already satisfied: urllib3\u003c1.27,\u003e=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision) (1.26.15)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision) (2.0.12)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests-\u003etorchvision) (2022.12.7)\n","Requirement already satisfied: mpmath\u003e=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy-\u003etorch) (1.3.0)\n","Building wheels for collected packages: lit\n","  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lit: filename=lit-16.0.0-py3-none-any.whl size=93601 sha256=526b3b2b69952a056db84efaa71f9d523627ef998fa26579d52d1d779114631a\n","  Stored in directory: /root/.cache/pip/wheels/c7/ee/80/1520ca86c3557f70e5504b802072f7fc3b0e2147f376b133ed\n","Successfully built lit\n","Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.13.1+cu116\n","    Uninstalling torch-1.13.1+cu116:\n","      Successfully uninstalled torch-1.13.1+cu116\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.14.1+cu116\n","    Uninstalling torchvision-0.14.1+cu116:\n","      Successfully uninstalled torchvision-0.14.1+cu116\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torchtext 0.14.1 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n","torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 2.0.0 which is incompatible.\n","fastai 2.7.11 requires torch\u003c1.14,\u003e=1.7, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed lit-16.0.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchvision-0.15.1 triton-2.0.0\n"]}],"source":["# important: update to torch 2.0 s.t. pre_hooks are available\n","!pip install torch torchvision -U"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dw8ugrCeiNfs"},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch Version:  2.0.0+cu117\n","Torchvision Version:  0.15.1+cu117\n"]}],"source":["import torch\n","from torch import nn\n","from torch.utils.data import DataLoader,TensorDataset,random_split\n","from torchvision import datasets, transforms\n","\n","import matplotlib.pyplot as plt\n","import torchvision\n","import numpy as np\n","import time, os, copy, random\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"]},{"cell_type":"markdown","metadata":{"id":"SjqoNbkwixux"},"source":["# Create artifical data"]},{"cell_type":"markdown","metadata":{"id":"CbKbEy-8dGUv"},"source":["Set random seeds."]},{"cell_type":"code","execution_count":117,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1679323473575,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"Mn7f1HwtwAJd"},"outputs":[],"source":["torch.manual_seed(0)\n","random.seed(0)\n","np.random.seed(0)"]},{"cell_type":"markdown","metadata":{"id":"QorOfAM8dIUY"},"source":["Set the number of batches and the batch size. For these early tests, 2 batches of size 3 should give good insights while not being to complicated."]},{"cell_type":"code","execution_count":118,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1679323473575,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"gA-mAFABomFA"},"outputs":[],"source":["n_batches = 5\n","batch_size = 3\n","n_samples = n_batches * batch_size"]},{"cell_type":"markdown","metadata":{"id":"w7LJIGvLdbll"},"source":["The network architecture, initial weights and test data is similar to this source:\n","https://www.kaggle.com/code/sironghuang/understanding-pytorch-hooks.\n","\n","In the linked notebook, only one datapoint is evaluated. Here, this datapoint will be repeated to include the effects of using batches."]},{"cell_type":"code","execution_count":119,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1679323473575,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"jsDhED5Ai0Ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["dataset size :torch.Size([15, 2])\n","single sample, size: torch.Size([2]) | values: tensor([0.0500, 0.1000])\n"]}],"source":["artifical_data = torch.empty((n_samples,2))\n","artifical_data[:,0] = 0.05\n","artifical_data[:,1] = 0.1\n","print(f'dataset size :{artifical_data.shape}')\n","print(f'single sample, size: {artifical_data[0,:].shape} | values: {artifical_data[0,:]}')"]},{"cell_type":"code","execution_count":120,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":225,"status":"ok","timestamp":1679323722449,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"vbSsuujJ7CsS","outputId":"d4502a69-0b60-4814-f8b2-d2d41545e882"},"outputs":[{"name":"stdout","output_type":"stream","text":["label set size :torch.Size([15, 2])\n","single label, size: torch.Size([2]) | values: tensor([0.0100, 0.9900])\n"]}],"source":["artifical_labels = torch.empty_like(artifical_data)\n","artifical_labels[:,0] = 0.01\n","artifical_labels[:,1] = 0.99\n","print(f'label set size :{artifical_labels.shape}')\n","print(f'single label, size: {artifical_labels[0,:].shape} | values: {artifical_labels[0,:]}')"]},{"cell_type":"markdown","metadata":{"id":"6eY_iCiAgdEH"},"source":["Next, the datasets and dataloader are created from the tensors. The first 4*batch_size samples are being used as the training set and the remaining batch_size samples are the test set. The splitting of datasets is not necessary for now but will make extension easy later on.\n","\n","Tensordata requires a 2D tensor, where each line represents one training sample. Targets may be 1-D or 2-D."]},{"cell_type":"code","execution_count":121,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":557,"status":"ok","timestamp":1679324013576,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"4j4s1b5ovWul"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of batches in the training set is 12\n"]}],"source":["train_set = TensorDataset(artifical_data[:4*batch_size,], artifical_labels[:4*batch_size,])\n","train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n","print(f'Number of batches in the training set is {len(train_set)}')"]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":347,"status":"ok","timestamp":1679324013919,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"dvcyG4rszTr9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of batches in the evaluation set is 3\n"]}],"source":["eval_set = TensorDataset(artifical_data[4*batch_size:,], artifical_labels[4*batch_size:,])\n","eval_loader = DataLoader(train_set, batch_size=batch_size, shuffle=False)\n","print(f'Number of batches in the evaluation set is {len(eval_set)}')"]},{"cell_type":"code","execution_count":123,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1679324013920,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"rwHDPE_ezrrK"},"outputs":[],"source":["dataloaders = {'train':train_loader,\n","               'eval':eval_loader}"]},{"cell_type":"markdown","metadata":{"id":"o0iH0l_Fj7e1"},"source":["# Create sample model"]},{"cell_type":"markdown","metadata":{"id":"IAA6XFQrXyd_"},"source":["The base model architecture and weights are taken from [here](https://www.kaggle.com/code/sironghuang/understanding-pytorch-hooks) for reference.\n","\n","Here, the architecture is extended by a dropout layer."]},{"cell_type":"code","execution_count":124,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":251,"status":"ok","timestamp":1679325408560,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"8aSvRv4aj-jN"},"outputs":[],"source":["class TestModel(nn.Module):\n","  def __init__(self, dropout_rate = 0.5):\n","        super().__init__()\n","        # self.flatten = nn.Flatten()\n","        self.fc1 = nn.Linear(2,2)\n","        self.s1 = nn.Sigmoid()\n","        self.do1 = nn.Dropout(p=0.5)\n","        self.fc2 = nn.Linear(2,2)\n","        self.s2 = nn.Sigmoid()\n","        self.fc1.weight = torch.nn.Parameter(torch.Tensor([[0.15,0.2],[0.250,0.30]]))\n","        self.fc1.bias = torch.nn.Parameter(torch.Tensor([0.35]))\n","        self.fc2.weight = torch.nn.Parameter(torch.Tensor([[0.4,0.45],[0.5,0.55]]))\n","        self.fc2.bias = torch.nn.Parameter(torch.Tensor([0.6]))\n","\n","  def forward(self, x):\n","      # x = self.flatten(x)\n","      x= self.fc1(x)\n","      x = self.s1(x)\n","      \n","      \n","      x = self.do1(x)\n","      x= self.fc2(x)\n","      x = self.s2(x)\n","      return x"]},{"cell_type":"code","execution_count":125,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1679325408912,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"QRCU-Okzm2NS"},"outputs":[{"name":"stdout","output_type":"stream","text":["TestModel(\n","  (fc1): Linear(in_features=2, out_features=2, bias=True)\n","  (s1): Sigmoid()\n","  (do1): Dropout(p=0.5, inplace=False)\n","  (fc2): Linear(in_features=2, out_features=2, bias=True)\n","  (s2): Sigmoid()\n",")\n"]}],"source":["model = TestModel()\n","print(model)"]},{"cell_type":"code","execution_count":126,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1679325410017,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"MMae-esXuBlq"},"outputs":[{"name":"stdout","output_type":"stream","text":["Layer: fc1.weight | Size: torch.Size([2, 2]) | Values : tensor([[0.1500, 0.2000],\n","        [0.2500, 0.3000]], grad_fn=\u003cSliceBackward0\u003e) \n","\n","Layer: fc1.bias | Size: torch.Size([1]) | Values : tensor([0.3500], grad_fn=\u003cSliceBackward0\u003e) \n","\n","Layer: fc2.weight | Size: torch.Size([2, 2]) | Values : tensor([[0.4000, 0.4500],\n","        [0.5000, 0.5500]], grad_fn=\u003cSliceBackward0\u003e) \n","\n","Layer: fc2.bias | Size: torch.Size([1]) | Values : tensor([0.6000], grad_fn=\u003cSliceBackward0\u003e) \n","\n"]}],"source":["for name, param in model.named_parameters():\n","    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"]},{"cell_type":"markdown","metadata":{"id":"80KDZLJws763"},"source":["# Prepare optimizer and loss function"]},{"cell_type":"code","execution_count":127,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1679325458274,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"EltLsz4_tYEN"},"outputs":[],"source":["sgd_parameters = {\n","    'lr':1e-3,        # undefined\n","    'momentum':0,   # 0\n","    'dampening':0,    # 0\n","    'weight_decay':0  # 0\n","}\n","optimizer = torch.optim.SGD(model.parameters(), **sgd_parameters)"]},{"cell_type":"code","execution_count":128,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1679325465464,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"B3US8RnNthm-"},"outputs":[],"source":["loss_fn = nn.MSELoss()"]},{"cell_type":"markdown","metadata":{"id":"pyeXQRZ5tf8z"},"source":["# Hooks"]},{"cell_type":"markdown","metadata":{"id":"EF6CyBtEth72"},"source":["Create two hooks for debugging purposes:\n","- the forward hook will print the input and output tensor produced during the forward pass.\n","- the backward hook will print the gradient of the output (the gradient coming from the loss) and the gradient input (the gradient used for following calculations closer to the input layers) during the backward pass. "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"_FaKBHjTte5A"},"outputs":[],"source":["def forward_debug_hook(module, input, output):\n","  print('forward hook')\n","  print(input)\n","  print(output)\n","\n","def backward_debug_hook(module, grad_input, grad_output):\n","   print('backward hook')\n","   print(grad_input)\n","   print(grad_output)"]},{"cell_type":"markdown","metadata":{"id":"DeJbEpNJtjDy"},"source":["Another hook is used to extract the unregularized gradient. The hook is supposed to catch the output gradient (the gradient coming from the loss) when reaching the logits layer (last fc layer of the model).\n","\n","For this, the hook is created as a class to store the gradient for later use. \n","\n","Note that the hook will be attached to the layer the whole time and the stored gradient will simply be overwritten.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ipquUx53tjyN"},"outputs":[],"source":["class Catch_Hook():\n","  def __init__(self, module):\n","    self.hook = module.register_full_backward_hook(self.hook_fn)\n","\n","  def hook_fn(self, module, grad_input, grad_output):\n","    self.caught_grad = grad_output\n","    print('caught a gradient')\n","\n","  def close(self):\n","    self.hook.remove()\n","\n","affected_layer = model.fc2\n","catch_hook = Catch_Hook(affected_layer)"]},{"cell_type":"markdown","metadata":{"id":"t0iC6PnGtlxB"},"source":["Re-insertion of the gradient is a little bit more tricky.\n","\n","By using the return statement in the backward hook, the gradient can be manipulated. There are two possibilities:\n","1. using the full_backward_hook will insert the gradient in the return statement as the ***input gradient*** (see [here](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_hook))\n","2. using the full_backward_hook will insert the gradient in the return statement as the ***output gradient*** (see [here](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.register_full_backward_pre_hook))\n","\n","In the logit case, we want to replace the gradient dLoss/dLogits, which is in this case excactly the output gradient of the corresponding layer. If one was to replace the input_gradient, this would essentialy replace the gradient for dLoss/dLogits*dLogits/dInputsOfLogits.\n","\n","Therefore one should use the backward_pre_hook (which is making troubles atm).\n","\n","Additionally, we want don't want to apply this hook during both the unregularized and the regularized run, as we don't want to replace it during the unregularized run. We will therefore register and remove the hook in the training loop.\n","\n","If you want to test the hook, you can use the commented code snippet at the end. Don't forget to remove the hook before applying a new one."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"ht57TVZxtnyo"},"outputs":[],"source":["class Insert_Hook():\n","  def __init__(self, module, new_grad_output):\n","    self.new_grad_output = new_grad_output\n","    # use prepend=True so that this is definetly the first hook being applied\n","    self.hook = module.register_full_backward_hook(self.hook_fn)\n","\n","  def hook_fn(self, module, grad_input, grad_output):\n","    print('inserted gradient')\n","    # simply return the previously caught grad_output\n","    # this will replace the current grad_output (if prehook is used)\n","    # if non-pre hook is used, grad_input will be replaced (not desire in our case)\n","    return self.new_grad_output\n","  \n","  def close(self):\n","    self.hook.remove()\n","\n","# artifical_grad = (torch.ones([3,2]),)\n","# print(artifical_grad)\n","# insert_hook = Insert_Hook(affected_layer,artifical_grad)"]},{"cell_type":"markdown","metadata":{"id":"IFVjXtIsuYNt"},"source":["# Model training"]},{"cell_type":"markdown","metadata":{"id":"2vnUDQ886Q7b"},"source":["Comments on the training loops are inside the code.\n","\n","The general idea for each batch is:\n","First run "]},{"cell_type":"code","execution_count":113,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1679322537862,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"5l3DWY0euaYR"},"outputs":[],"source":["def train_model(model, dataloaders, loss_fn, optimizer, num_epochs=5):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    n_train_batches = len(dataloaders['train'])\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        ########## train phase ##########\n","        phase = 'train'\n","        model.train()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for batch, (inputs, labels) in enumerate(dataloaders[phase]):\n","          optimizer.zero_grad()\n","\n","          handlef = affected_layer.register_forward_hook(forward_debug_hook)\n","          handleb = affected_layer.register_full_backward_hook(backward_debug_hook)\n","\n","          #++++++++ catch unregularized gradient ++++++++#\n","          print('*'*5 + 'unregularized run' + '*'*5)\n","          model.eval()\n","          outputs = model(inputs)\n","          loss = loss_fn(outputs, labels.float())\n","          loss.backward()\n","          new_grad_output = catch_hook.caught_grad\n","          \n","          model.train()\n","          optimizer.zero_grad()\n","          #++++++++ \\catch unregularized gradient ++++++++#\n","\n","          #++++++++ prepare insertion of unregularized gradient ++++++++#\n","          handleb.remove()\n","          insert_hook = Insert_Hook(affected_layer,new_grad_output)\n","          handleb = affected_layer.register_full_backward_hook(backward_debug_hook)\n","          #++++++++ \\prepare insertion of unregularized gradient ++++++++#\n","          \n","          # Get model outputs and calculate loss\n","          print('*'*5 + 'forward pass' + '*'*5)\n","          outputs = model(inputs)\n","          print('outputs')\n","          print(outputs)\n","\n","          # outputs.backward(torch.tensor([[0.7414,-0.2171],[0.7414,-0.2171],[0.7414,-0.2171]],dtype=torch.float),retain_graph=True)\n","\n","          print('*'*5 + 'loss calculation' + '*'*5)\n","          loss = loss_fn(outputs, labels.float())\n","          print('loss')\n","          print(loss)\n","          # print('weights grad')\n","          # print(affected_layer.weight.grad)\n","          # print('bias grad')\n","          # print(affected_layer.bias.grad)\n","\n","          preds = (outputs\u003e0.5).int()\n","          \n","\n","          # backward + optimize\n","          print('*'*5 + 'backward pass' + '*'*5)\n","          \n","          # print(affected_layer._backward_hooks)\n","          loss.backward()          \n","          print('weights grad')\n","          print(affected_layer.weight.grad)\n","          print('bias grad')\n","          print(affected_layer.bias.grad)\n","\n","          insert_hook.close()\n","          handlef.remove()\n","          handleb.remove()\n","\n","          # print(affected_layer._backward_hooks)\n","          optimizer.step()\n","\n","          running_loss += loss.item() * inputs.size(0)\n","          running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","        ########## eval phase ##########\n","        phase = 'eval'\n","        model.eval()\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for batch, (inputs, labels) in enumerate(dataloaders[phase]):\n","          # disable gradient tracking for speedup\n","          with torch.set_grad_enabled(phase == 'train'):\n","            outputs = model(inputs)\n","            loss = loss_fn(outputs, labels.float())\n","            preds = (outputs\u003e0.5).int()\n","\n","          running_loss += loss.item() * inputs.size(0)\n","          running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","        epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))  \n","\n","        val_acc_history.append(epoch_acc)\n","        print()\n","\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","\n","    return val_acc_history"]},{"cell_type":"code","execution_count":114,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1679322537863,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"kLVefwl04gyl"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 0/0\n","----------\n","*****unregularized run*****\n","forward hook\n","(tensor([[0.5933, 0.5969],\n","        [0.5933, 0.5969],\n","        [0.5933, 0.5969]], grad_fn=\u003cBackwardHookFunctionBackward\u003e),)\n","tensor([[1.1059, 1.2249],\n","        [1.1059, 1.2249],\n","        [1.1059, 1.2249]], grad_fn=\u003cAddmmBackward0\u003e)\n","caught a gradient\n","backward hook\n","(tensor([[0.0121, 0.0138],\n","        [0.0121, 0.0138],\n","        [0.0121, 0.0138]]),)\n","(tensor([[ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127]]),)\n","*****forward pass*****\n","forward hook\n","(tensor([[0.0000, 1.1938],\n","        [1.1865, 1.1938],\n","        [1.1865, 0.0000]], grad_fn=\u003cBackwardHookFunctionBackward\u003e),)\n","tensor([[1.1372, 1.2566],\n","        [1.6118, 1.8498],\n","        [1.0746, 1.1933]], grad_fn=\u003cAddmmBackward0\u003e)\n","outputs\n","tensor([[0.7572, 0.7784],\n","        [0.8337, 0.8641],\n","        [0.7455, 0.7673]], grad_fn=\u003cSigmoidBackward0\u003e)\n","*****loss calculation*****\n","loss\n","tensor(0.3146, grad_fn=\u003cMseLossBackward0\u003e)\n","*****backward pass*****\n","caught a gradient\n","inserted gradient\n","backward hook\n","(tensor([[ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127]]),)\n","(tensor([[ 0.0458, -0.0122],\n","        [ 0.0381, -0.0049],\n","        [ 0.0465, -0.0133]]),)\n","weights grad\n","tensor([[ 0.1004,  0.1001],\n","        [-0.0216, -0.0204]])\n","bias grad\n","tensor([0.1000])\n","*****unregularized run*****\n","forward hook\n","(tensor([[0.5933, 0.5969],\n","        [0.5933, 0.5969],\n","        [0.5933, 0.5969]], grad_fn=\u003cBackwardHookFunctionBackward\u003e),)\n","tensor([[1.1057, 1.2248],\n","        [1.1057, 1.2248],\n","        [1.1057, 1.2248]], grad_fn=\u003cAddmmBackward0\u003e)\n","caught a gradient\n","backward hook\n","(tensor([[0.0121, 0.0138],\n","        [0.0121, 0.0138],\n","        [0.0121, 0.0138]]),)\n","(tensor([[ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127]]),)\n","*****forward pass*****\n","forward hook\n","(tensor([[1.1865, 0.0000],\n","        [1.1865, 1.1938],\n","        [1.1865, 0.0000]], grad_fn=\u003cBackwardHookFunctionBackward\u003e),)\n","tensor([[1.0744, 1.1932],\n","        [1.6115, 1.8498],\n","        [1.0744, 1.1932]], grad_fn=\u003cAddmmBackward0\u003e)\n","outputs\n","tensor([[0.7454, 0.7673],\n","        [0.8336, 0.8641],\n","        [0.7454, 0.7673]], grad_fn=\u003cSigmoidBackward0\u003e)\n","*****loss calculation*****\n","loss\n","tensor(0.3125, grad_fn=\u003cMseLossBackward0\u003e)\n","*****backward pass*****\n","caught a gradient\n","inserted gradient\n","backward hook\n","(tensor([[ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127]]),)\n","(tensor([[ 0.0465, -0.0133],\n","        [ 0.0381, -0.0049],\n","        [ 0.0465, -0.0133]]),)\n","weights grad\n","tensor([[ 0.1556,  0.0455],\n","        [-0.0373, -0.0059]])\n","bias grad\n","tensor([0.0997])\n","*****unregularized run*****\n","forward hook\n","(tensor([[0.5932, 0.5969],\n","        [0.5932, 0.5969],\n","        [0.5932, 0.5969]], grad_fn=\u003cBackwardHookFunctionBackward\u003e),)\n","tensor([[1.1054, 1.2247],\n","        [1.1054, 1.2247],\n","        [1.1054, 1.2247]], grad_fn=\u003cAddmmBackward0\u003e)\n","caught a gradient\n","backward hook\n","(tensor([[0.0121, 0.0138],\n","        [0.0121, 0.0138],\n","        [0.0121, 0.0138]]),)\n","(tensor([[ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127]]),)\n","*****forward pass*****\n","forward hook\n","(tensor([[0.0000, 0.0000],\n","        [0.0000, 1.1937],\n","        [1.1865, 0.0000]], grad_fn=\u003cBackwardHookFunctionBackward\u003e),)\n","tensor([[0.5998, 0.5998],\n","        [1.1368, 1.2564],\n","        [1.0741, 1.1931]], grad_fn=\u003cAddmmBackward0\u003e)\n","outputs\n","tensor([[0.6456, 0.6456],\n","        [0.7571, 0.7784],\n","        [0.7454, 0.7673]], grad_fn=\u003cSigmoidBackward0\u003e)\n","*****loss calculation*****\n","loss\n","tensor(0.2860, grad_fn=\u003cMseLossBackward0\u003e)\n","*****backward pass*****\n","caught a gradient\n","inserted gradient\n","backward hook\n","(tensor([[ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127]]),)\n","(tensor([[ 0.0485, -0.0263],\n","        [ 0.0458, -0.0122],\n","        [ 0.0465, -0.0133]]),)\n","weights grad\n","tensor([[ 0.0552,  0.0547],\n","        [-0.0157, -0.0145]])\n","bias grad\n","tensor([0.0891])\n","*****unregularized run*****\n","forward hook\n","(tensor([[0.5932, 0.5969],\n","        [0.5932, 0.5969],\n","        [0.5932, 0.5969]], grad_fn=\u003cBackwardHookFunctionBackward\u003e),)\n","tensor([[1.1053, 1.2247],\n","        [1.1053, 1.2247],\n","        [1.1053, 1.2247]], grad_fn=\u003cAddmmBackward0\u003e)\n","caught a gradient\n","backward hook\n","(tensor([[0.0121, 0.0138],\n","        [0.0121, 0.0138],\n","        [0.0121, 0.0138]]),)\n","(tensor([[ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127]]),)\n","*****forward pass*****\n","forward hook\n","(tensor([[0.0000, 1.1937],\n","        [1.1865, 1.1937],\n","        [1.1865, 0.0000]], grad_fn=\u003cBackwardHookFunctionBackward\u003e),)\n","tensor([[1.1366, 1.2563],\n","        [1.6109, 1.8496],\n","        [1.0739, 1.1930]], grad_fn=\u003cAddmmBackward0\u003e)\n","outputs\n","tensor([[0.7571, 0.7784],\n","        [0.8335, 0.8641],\n","        [0.7453, 0.7673]], grad_fn=\u003cSigmoidBackward0\u003e)\n","*****loss calculation*****\n","loss\n","tensor(0.3145, grad_fn=\u003cMseLossBackward0\u003e)\n","*****backward pass*****\n","caught a gradient\n","inserted gradient\n","backward hook\n","(tensor([[ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127]]),)\n","(tensor([[ 0.0458, -0.0122],\n","        [ 0.0381, -0.0049],\n","        [ 0.0465, -0.0133]]),)\n","weights grad\n","tensor([[ 0.1004,  0.1001],\n","        [-0.0216, -0.0204]])\n","bias grad\n","tensor([0.1001])\n","train Loss: 0.3069 Acc: 0.0000\n","eval Loss: 0.2983 Acc: 0.0000\n","\n","Training complete in 0m 0s\n"]}],"source":["hist = train_model(model,\n","                   dataloaders,\n","                   loss_fn,\n","                   optimizer,\n","                   num_epochs=1\n","                   )"]},{"cell_type":"code","execution_count":115,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1679322537863,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"tsdmhXg0wgRj","outputId":"abbbe8d0-3c73-4ea2-aa0a-e8a3cf3a79aa"},"outputs":[{"name":"stdout","output_type":"stream","text":["OrderedDict([(110, \u003cbound method Catch_Hook.hook_fn of \u003c__main__.Catch_Hook object at 0x7f7362bd7130\u003e\u003e)])\n","(tensor([[ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127],\n","        [ 0.0462, -0.0127]]),)\n","OrderedDict()\n"]}],"source":["print(affected_layer._backward_hooks)\n","print(catch_hook.caught_grad)\n","catch_hook.close()\n","print(affected_layer._backward_hooks)"]},{"cell_type":"markdown","metadata":{"id":"jyREiA7usUCM"},"source":["Erkenntnisse:\n","- layer.weight.grad wird erst in backward() befüllt.\n","- Im hook: gradient_out ist der bisherige **Gesamt**gradient. gradient_in ist  gradient_out*dgradient_out/dgradient_in.\n","- Der gradient für z.B. weight wird berechnet durch entsprechendes summe_batch(gradient_out*dgradient_out/dgewicht).\n","- um also den zur Idee passenden gradienten abzufangen, nutze einen full_backward_hook auf der passenden layer (hier z.B. fc2) und extrahiere den gradient_out.\n","- das wiedereinsetzen sollte ebenfalls durch einen hook funktionieren\n"]},{"cell_type":"markdown","metadata":{"id":"CJhpHOt4tEjV"},"source":["# Miscellanous code\n","This is mostly code that was used to comprehend and retrace what is happening under the hood."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1679230159503,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"D7u0nvUbm9w8"},"outputs":[],"source":["model.eval()\n","output = model(artifical_data_sample)\n","print(output.shape)\n","print(output)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1679230159503,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"fIrdtkvpn63q"},"outputs":[],"source":["output_batch = model(artifical_data_batch)\n","print(output_batch.shape)\n","print(output_batch)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1679230159504,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"_Wxuzr7jpKYV"},"outputs":[],"source":["for name, parameter in model.linear_relu_stack.named_parameters():\n","  print(name)\n","  print(parameter)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1679230159504,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"P6EZSxjRprdE"},"outputs":[],"source":["input = artifical_data_sample = artifical_data_batch[:2,:]\n","print(input)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1679230159505,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"275NyE9hqL0L"},"outputs":[],"source":["after0 = model.linear_relu_stack[0](input)\n","# = print(torch.matmul(model.linear_relu_stack[0].weight,input.t())+model.linear_relu_stack[0].bias)\n","after0"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1679230159505,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"dNXYjanTq9ys"},"outputs":[],"source":["after1 = model.linear_relu_stack[1](after0)\n","after1"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1679230159506,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"2sFL71OIrmdT"},"outputs":[],"source":["after2 = model.linear_relu_stack[2](after1)\n","after2"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":21,"status":"aborted","timestamp":1679230159506,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"bBfMWn_JsNMT"},"outputs":[],"source":["after3 = model.linear_relu_stack[3](after2)\n","after3"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1679230159506,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"59tXF250sUoo"},"outputs":[],"source":["after4 = model.linear_relu_stack[4](after3)\n","after4"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":20,"status":"aborted","timestamp":1679230159507,"user":{"displayName":"Ricupuch","userId":"12829564591003013695"},"user_tz":-60},"id":"8YIBqksLsXlm"},"outputs":[],"source":["after5 = model.linear_relu_stack[5](after4)\n","after5"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOb/VZ9V/wwTFYl8dzNxcCb","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}